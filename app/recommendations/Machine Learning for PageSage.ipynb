{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Page Sage\n",
    "\n",
    "This notebook should serve as a tutorial and explanatory process for the Page Sage recommendation algorithm.\n",
    "\n",
    "First, let's create some preprocessors for the data since we know what format to expect them.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class BookClassifier(object):\n",
    "    def __init__(self, volumes=[], ratings=[]):\n",
    "        if (len(volumes) == 0) or (len(ratings) == 0):\n",
    "            raise ValueError('Initial values cannot be zero')\n",
    "        if (len(volumes) != len(ratings)):\n",
    "            raise ValueError('Labels and data must have the same length')\n",
    "\n",
    "        self.volumes = volumes\n",
    "        self.ratings = ratings\n",
    "        self.__book_data = []\n",
    "        self.categories = dict()\n",
    "        self.maturities = dict()\n",
    "        self.books = []\n",
    "        self.X_train, self.y_train = [],[]\n",
    "        self.__model = None\n",
    "        self.set_up()\n",
    "\n",
    "\n",
    "    def set_up(self):\n",
    "        self.__book_data = self.__pull_books(self.volumes, self.ratings)\n",
    "        self.__find_categories(self.__book_data)\n",
    "        #self.maturities = self.__find_maturities(self.book_data)\n",
    "        self.books = self.__reformat(self.__book_data)\n",
    "        self.X_train, self.y_train = self.__x_y_train(self.books)\n",
    "\n",
    "\n",
    "    def __pull_books(self, volumes, labels=[]):\n",
    "        book_data = []\n",
    "        search_key = str(os.environ.get('SEARCH_KEY'))\n",
    "        baseURL = 'https://www.googleapis.com/books/v1/volumes/'\n",
    "        endURL = '?key=' + search_key\n",
    "\n",
    "        headers = {'Accept': 'application/json'}\n",
    "\n",
    "        for index, volume in enumerate(volumes):\n",
    "            url = baseURL + str(volume) + endURL\n",
    "\n",
    "            resp = requests.get(url, params=headers)\n",
    "            if not resp.ok:\n",
    "                raise ValueError('Response error; could not make call')\n",
    "            book_info = resp.json()\n",
    "            new_book = {}\n",
    "\n",
    "            try:\n",
    "                page_count  =  int(book_info['volumeInfo']['pageCount'])\n",
    "            except (KeyError):\n",
    "                page_count = 100\n",
    "\n",
    "            try:\n",
    "                categories = self.__category_preprocessor(book_info['volumeInfo']['categories'])\n",
    "            except (KeyError):\n",
    "                categories = self.__category_preprocessor(['Fiction'])\n",
    "\n",
    "            try:\n",
    "                average_rating = float(book_info['volumeInfo']['averageRating'])\n",
    "            except (KeyError):\n",
    "                average_rating = float(3)\n",
    "\n",
    "            try:\n",
    "                ratings_count = int(book_info['volumeInfo']['ratingsCount'])\n",
    "            except (KeyError):\n",
    "                ratings_count = int(0)\n",
    "\n",
    "            '''\n",
    "            try:\n",
    "                maturity_rating = book_info['volumeInfo']['maturityRating']\n",
    "            except (KeyError):\n",
    "                maturity_rating = 'NOT_MATURE'\n",
    "            '''\n",
    "\n",
    "            if labels != []:\n",
    "                book_data.append({\n",
    "                    'user_rating'       : labels[index],\n",
    "                    'page_count'        : page_count,\n",
    "                    'categories'        : categories,\n",
    "                    'average_rating'    : average_rating,\n",
    "                    'ratings_count'     : ratings_count\n",
    "                    #'maturity_rating'   : maturity_rating\n",
    "                })\n",
    "            else:\n",
    "                book_data.append({\n",
    "                    'page_count'        : page_count,\n",
    "                    'categories'        : categories,\n",
    "                    'average_rating'    : average_rating,\n",
    "                    'ratings_count'     : ratings_count\n",
    "                    #'maturity_rating'   : maturity_rating\n",
    "                })\n",
    "\n",
    "        return book_data\n",
    "\n",
    "\n",
    "    def __category_preprocessor(self, categories):\n",
    "        if type(categories) != type(list()):\n",
    "            return categories\n",
    "        \n",
    "        cats = []\n",
    "        for category in categories:\n",
    "            cat_split = category.split('/')\n",
    "            for cat in cat_split:\n",
    "                cat = cat.strip().lower()\n",
    "                if cat not in cats:\n",
    "                    cats.append(cat)\n",
    "\n",
    "        return cats\n",
    "\n",
    "\n",
    "    def __find_categories(self, books):\n",
    "        index = 2\n",
    "        for book in books:\n",
    "            for category in book['categories']:\n",
    "                if category not in self.categories.keys():\n",
    "                    self.categories[category] = index\n",
    "                    index += 1\n",
    "\n",
    "\n",
    "    def __find_maturities(self, books):\n",
    "        index = 0\n",
    "        for book in books:\n",
    "            if book['maturity_rating'] not in self.maturities:\n",
    "                self.maturities[book['maturity_rating']] = index\n",
    "                index += 1\n",
    "\n",
    "\n",
    "    def __reformat(self, books):\n",
    "        new_books = []\n",
    "        for book in books:\n",
    "            new_book = []\n",
    "            for data in book:\n",
    "                if 'categories' == data:\n",
    "                    for category in self.categories:\n",
    "                        new_book.append(0)\n",
    "                elif 'maturity_rating' == data:\n",
    "                    for maturity in self.maturities:\n",
    "                        new_book.append(0)\n",
    "                else:\n",
    "                    new_book.append(book[data])\n",
    "            new_books.append(new_book)\n",
    "        for index, book in enumerate(new_books):\n",
    "            for category in self.categories:\n",
    "                if category in books[index]['categories']:\n",
    "                    new_books[index][self.categories[category]] = books[index]['categories'].count(category)\n",
    "            '''for maturities in self.maturities:\n",
    "                if maturity in books[index]['maturities']:\n",
    "                    new_books[index][len(maturities[maturity])\n",
    "            '''\n",
    "        return new_books\n",
    "\n",
    "\n",
    "    def __x_y_train(self, books):\n",
    "        books = deepcopy(books)\n",
    "        labels = []\n",
    "        new_books = []\n",
    "\n",
    "        for book in books:\n",
    "            labels.append(np.array(int(book.pop(0))))\n",
    "            new_books.append(book)\n",
    "\n",
    "        return (np.asarray(new_books), np.asarray(labels))\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Dense(units=20, input_dim=self.X_train.shape[1],\n",
    "                                     kernel_initializer='glorot_uniform',\n",
    "                                     bias_initializer='zeros',\n",
    "                                     activation='selu'))\n",
    "\n",
    "        model.add(keras.layers.Dense(units=20, input_dim=self.X_train.shape[1],\n",
    "                                     kernel_initializer='glorot_uniform',\n",
    "                                     bias_initializer='zeros',\n",
    "                                     activation='selu'))\n",
    "\n",
    "        model.add(keras.layers.Dense(units=1, input_dim=self.X_train.shape[1],\n",
    "                                     kernel_initializer='glorot_uniform',\n",
    "                                     bias_initializer='zeros',\n",
    "                                     activation='softmax'))\n",
    "\n",
    "        sgd_optimizer = keras.optimizers.SGD(lr=0.001, decay=1e-7, momentum=0.9)\n",
    "\n",
    "        model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy')\n",
    "\n",
    "        history = model.fit(self.X_train, self.y_train,\n",
    "                            batch_size=3, epochs=15, verbose=1,\n",
    "                            validation_split=0.1)\n",
    "\n",
    "        self.y_train_pred = model.predict_classes(self.X_train, verbose=0)\n",
    "\n",
    "        self.__model = model\n",
    "\n",
    "        \n",
    "    def feature_space(self):\n",
    "        return str(self.X_train.shape[0]) + ', ' + str(self.X_train.shape[1])\n",
    "    \n",
    "    \n",
    "    def train_acc(self):\n",
    "        print(self.y_train_pred)\n",
    "        print(self.y_train)\n",
    "        return np.sum(self.y_train_pred == self.y_train, axis=0)\n",
    "    \n",
    "        \n",
    "    def __preprocess_book(self, book):\n",
    "        book = deepcopy(book)\n",
    "        book_data = [self.__pull_books(book)]\n",
    "        \n",
    "        return np.asarray(self.__reformat(book))\n",
    "\n",
    "\n",
    "    def predict(self, book=[]):\n",
    "        if book == [] or book:\n",
    "            raise ValueError('Parameter cannot be an empty book')\n",
    "        if self.__model == None:\n",
    "            raise ValueError('Classifier needs training before predictions')\n",
    "        if type(book) != type(str()):\n",
    "            raise ValueError('Book must a valid volumeID of type \"String\"')\n",
    "\n",
    "        X_sample = __preprocess_book(book)\n",
    "        \n",
    "        return self.__model.predict_classes(X_sample, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of volumes:\t 61\n",
      "Length of labels:\t 61\n"
     ]
    }
   ],
   "source": [
    "test_volumes = []\n",
    "test_labels = []\n",
    "\n",
    "with open('emily_books_2_tier.txt', 'r') as test_file:\n",
    "    for line in test_file:\n",
    "        items = line.split(',')\n",
    "        test_volumes.append(items[0])\n",
    "        test_labels.append(items[1].strip())\n",
    "\n",
    "print('Length of volumes:\\t', len(test_volumes))\n",
    "print('Length of labels:\\t', len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Response error;  could not  make call",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-2196a9d3c7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBookClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_volumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-6ec3cd8de52f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, volumes, ratings)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-6ec3cd8de52f>\u001b[0m in \u001b[0;36mset_up\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__book_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pull_books\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__find_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__book_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#self.maturities = self.__find_maturities(self.book_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-6ec3cd8de52f>\u001b[0m in \u001b[0;36m__pull_books\u001b[0;34m(self, volumes, labels)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Response error;  could not  make call'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mbook_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mnew_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Response error;  could not  make call"
     ]
    }
   ],
   "source": [
    "test_model = BookClassifier(test_volumes, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_model = deepcopy(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 7 samples\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 0s 430us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 0s 426us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 0s 556us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 0s 404us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 0s 443us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 0s 408us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 0s 487us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 0s 408us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 0s 391us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 0s 369us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 0s 476us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 0s 373us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 0s 388us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 0s 421us/step - loss: 6.4950 - val_loss: 15.9424\n"
     ]
    }
   ],
   "source": [
    "backup_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories {'fiction': 2}\n"
     ]
    }
   ],
   "source": [
    "print('Categories', backup_model.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,\n",
       "       61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backup_model.train_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
