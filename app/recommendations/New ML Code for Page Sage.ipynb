{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description and Categorical Based ML #\n",
    "\n",
    "Update to previous model with categorical and description based data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/peter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package names to /Users/peter/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "success = nltk.download('stopwords')\n",
    "success = nltk.download('names')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import names\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class BookClassifier(object):\n",
    "    def __init__(self, volumes=[], ratings=[]):\n",
    "        if (len(volumes) == 0) or (len(ratings) == 0):\n",
    "            raise ValueError('Initial values cannot be zero')\n",
    "        if (len(volumes) != len(ratings)):\n",
    "            raise ValueError('Labels and data must have the same length')\n",
    "\n",
    "        self.volumes = volumes\n",
    "        self.ratings = ratings\n",
    "        self.__book_data = []\n",
    "        self.categories = dict()\n",
    "        self.maturities = dict()\n",
    "        self.descriptions = dict()\n",
    "        self.books = []\n",
    "        self.X_train, self.y_train = [],[]\n",
    "        self.__model = None\n",
    "        self.description_set = set()\n",
    "        self.stop = stopwords.words('english')\n",
    "        self.name = [n.lower() for n in names.words()]\n",
    "        self.set_up()\n",
    "\n",
    "\n",
    "    def set_up(self):\n",
    "        self.__book_data = self.__pull_books(self.volumes, self.ratings)\n",
    "        self.__find_categories(self.__book_data)\n",
    "        #self.description_set.remove('')\n",
    "        self.__find_descriptions(self.__book_data)\n",
    "        #self.maturities = self.__find_maturities(self.book_data)\n",
    "        self.books = self.__reformat(self.__book_data)\n",
    "        self.X_train, self.y_train = self.__x_y_train(self.books)\n",
    "        ##self.scikit_kpca = KernelPCA(n_components=3, kernel='rbf')\n",
    "        ##self.X_train = self.scikit_kpca.fit_transform(self.X_train)\n",
    "\n",
    "\n",
    "    def __pull_books(self, volumes, labels=[]):\n",
    "        book_data = []\n",
    "        search_key = str(os.environ.get('SEARCH_KEY'))\n",
    "        baseURL = 'https://www.googleapis.com/books/v1/volumes/'\n",
    "        endURL = '?key=' + search_key\n",
    "\n",
    "        headers = {'Accept': 'application/json'}\n",
    "        if type(volumes) == type(str()):\n",
    "            volumes = [volumes]\n",
    "        \n",
    "        for index, volume in enumerate(volumes):\n",
    "            url = baseURL + str(volume) + endURL\n",
    "\n",
    "            resp = requests.get(url, params=headers)\n",
    "            if not resp.ok:\n",
    "                raise ValueError('Response error; could not make call')\n",
    "            book_info = resp.json()\n",
    "            new_book = {}\n",
    "\n",
    "            try:\n",
    "                page_count  =  int(book_info['volumeInfo']['pageCount'])\n",
    "            except (KeyError):\n",
    "                page_count = 100\n",
    "\n",
    "            try:\n",
    "                categories = self.__category_preprocessor(book_info['volumeInfo']['categories'])\n",
    "            except (KeyError):\n",
    "                categories = self.__category_preprocessor(['Fiction'])\n",
    "\n",
    "            try:\n",
    "                average_rating = float(book_info['volumeInfo']['averageRating'])\n",
    "            except (KeyError):\n",
    "                average_rating = float(3)\n",
    "\n",
    "            try:\n",
    "                ratings_count = int(book_info['volumeInfo']['ratingsCount'])\n",
    "            except (KeyError):\n",
    "                ratings_count = int(0)\n",
    "                \n",
    "            try:\n",
    "                description = self.__description_preprocessor(book_info['volumeInfo']['description'])\n",
    "            except (KeyError):\n",
    "                description = self.__description_preprocessor(' '.join(categories))\n",
    "\n",
    "            '''\n",
    "            try:\n",
    "                maturity_rating = book_info['volumeInfo']['maturityRating']\n",
    "            except (KeyError):\n",
    "                maturity_rating = 'NOT_MATURE'\n",
    "            '''\n",
    "\n",
    "            if labels != []:\n",
    "                book_data.append({\n",
    "                    'user_rating'       : labels[index],\n",
    "                    'page_count'        : page_count,\n",
    "                    'categories'        : categories,\n",
    "                    'average_rating'    : average_rating,\n",
    "                    'ratings_count'     : ratings_count,\n",
    "                    'description'       : description\n",
    "                    #'maturity_rating'   : maturity_rating\n",
    "                })\n",
    "                self.description_set = self.description_set.union(description)\n",
    "                #for word in description:\n",
    "                #    self.description_set.add(word)\n",
    "            else:\n",
    "                book_data.append({\n",
    "                    'page_count'        : page_count,\n",
    "                    'categories'        : categories,\n",
    "                    'average_rating'    : average_rating,\n",
    "                    'ratings_count'     : ratings_count,\n",
    "                    'description'       : description\n",
    "                    #'maturity_rating'   : maturity_rating\n",
    "                })\n",
    "\n",
    "        return book_data\n",
    "\n",
    "\n",
    "    def __category_preprocessor(self, categories):\n",
    "        if type(categories) != type(list()):\n",
    "            return categories\n",
    "        \n",
    "        cats = []\n",
    "        for category in categories:\n",
    "            cat_split = category.split('/')\n",
    "            for cat in cat_split:\n",
    "                cat = cat.strip().lower()\n",
    "                if cat not in cats:\n",
    "                    cats.append(cat)\n",
    "        return cats\n",
    "    \n",
    "\n",
    "    def __find_categories(self, books):\n",
    "        index = 2\n",
    "        for book in books:\n",
    "            for category in book['categories']:\n",
    "                if category not in self.categories.keys():\n",
    "                    self.categories[category] = index\n",
    "                    index += 1\n",
    "\n",
    "                    \n",
    "    ##################\n",
    "    # NLP Processing #\n",
    "    ##################\n",
    "    def __collect_and_trim_punctuation(self, book):\n",
    "        text = book\n",
    "        text = re.sub('<b>', ' ', text)\n",
    "        text = re.sub('<i>', ' ', text)\n",
    "        text = re.sub('</b>', ' ', text)\n",
    "        text = re.sub('</i>', ' ', text)\n",
    "        text = re.sub('<br>', ' ', text)\n",
    "        text = re.sub('<p>', ' ', text)\n",
    "        text = re.sub('</p>', ' ', text)\n",
    "        text = re.sub(',', ' ', text)\n",
    "        text = re.sub('\\\\xa0', ' ', text)\n",
    "        text = re.sub('★', ' ', text)\n",
    "        text = re.sub('-', ' ', text)\n",
    "        text = re.sub('[0-9]', ' ', text)\n",
    "        text = re.sub('\"', ' ', text)\n",
    "        text = re.sub(\"'\", ' ', text)\n",
    "        text = text.replace('.', ' ')\n",
    "        text = text.replace('(', ' ')\n",
    "        text = text.replace(')', ' ')\n",
    "        text = text.replace('-', ' ')\n",
    "        text = text.replace('…', ' ')\n",
    "        text = text.replace('[', ' ')\n",
    "        text = text.replace(']', ' ')\n",
    "        text = text.replace('#', ' ')\n",
    "        text = text.replace('$', ' ')\n",
    "        text = text.replace('—', ' ')\n",
    "        text = text.replace('\"', ' ')\n",
    "        text = text.replace(\"'\", ' ')\n",
    "        text = text.replace('&', ' ')\n",
    "        text = text.replace('!', ' ')\n",
    "        text = text.replace('•', ' ')\n",
    "        text = text.replace(';', ' ')\n",
    "        text = text.replace('–', ' ')\n",
    "        text = text.replace(':', ' ')\n",
    "        text = text.replace('“', ' ')\n",
    "        text = text.replace('”', ' ')\n",
    "        text = text.replace('?', ' ')\n",
    "        text = text.replace('>', ' ')\n",
    "        text = text.replace('<', ' ')\n",
    "        text = text.replace('/', ' ')\n",
    "        text = text.replace('’', ' ')\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    \n",
    "    def __porter_tokenizer(self, text):\n",
    "        text = re.sub('<[^>]*>', ' ', text)\n",
    "        text = self.__collect_and_trim_punctuation(text)\n",
    "        porter = [PorterStemmer().stem(text) for word in text.split()]\n",
    "        new_porter = set()\n",
    "        for p in porter:\n",
    "                #for word in p:\n",
    "                #    new_porter.add(word)\n",
    "                #continue\n",
    "            #if '.' in p:\n",
    "                #p = p.strip('.')\n",
    "            #    p = ''.join(p.split('.'))\n",
    "            if p != '':\n",
    "                new_porter.add(p)\n",
    "        #new_porter = [PorterStemmer(' '.join(new_porter)).stem(word) for word in new_porter]\n",
    "        return list(new_porter)\n",
    "           \n",
    "    \n",
    "    ### Edit this so that each individual string is preprocessed as it goes through\n",
    "    ### Actually, dCreate second function to edit at the end\n",
    "    def __description_preprocessor(self, description):\n",
    "        if type(description) != type(str()):\n",
    "            return description\n",
    "        tokenized_text = [w for w in self.__porter_tokenizer(description) if (w not in self.stop) and (w not in self.name)]\n",
    "        #desc = description.split(' ')\n",
    "        #new_desc = []\n",
    "        #for element in desc:\n",
    "        #    if element == ' ':\n",
    "        #        continue\n",
    "        #    new_desc.append(element)\n",
    "        #tokenized_text = [w for w in porter_tokenizer(full_text) if (w not in stop) and (w not in name)]\n",
    "        #print(str(tokenized_text))\n",
    "        tokenized_text = tokenized_text[0].split(' ')\n",
    "        tokenized_text = [w for w in tokenized_text if w != '']\n",
    "        return set(tokenized_text)\n",
    "\n",
    "                    \n",
    "    def __find_descriptions(self, books):\n",
    "        index = 2 + len(self.categories) + 2\n",
    "        for book in books:\n",
    "            for description in self.description_set:\n",
    "                if description not in self.descriptions.keys():\n",
    "                    self.descriptions[description] = index\n",
    "                    index += 1\n",
    "\n",
    "\n",
    "    def __find_maturities(self, books):\n",
    "        index = 0\n",
    "        for book in books:\n",
    "            if book['maturity_rating'] not in self.maturities:\n",
    "                self.maturities[book['maturity_rating']] = index\n",
    "                index += 1\n",
    "\n",
    "\n",
    "    def __reformat(self, books):\n",
    "        new_books = []\n",
    "        for book in books:\n",
    "            new_book = []\n",
    "            for data in book:\n",
    "                if 'categories' == data:\n",
    "                    for category in self.categories:\n",
    "                        new_book.append(0)\n",
    "                elif 'maturity_rating' == data:\n",
    "                    for maturity in self.maturities:\n",
    "                        new_book.append(0)\n",
    "                elif 'description' == data:\n",
    "                    for description in self.descriptions:\n",
    "                        new_book.append(0)\n",
    "                else:\n",
    "                    new_book.append(book[data])\n",
    "            new_books.append(new_book)\n",
    "        for index, book in enumerate(new_books):\n",
    "            for category in self.categories:\n",
    "                if category in books[index]['categories']:\n",
    "                    new_books[index][self.categories[category]] = books[index]['categories'].count(category)\n",
    "            for description in self.descriptions:\n",
    "                if description in books[index]['description']:\n",
    "                    new_books[index][self.descriptions[description]] = 1\n",
    "            '''for maturities in self.maturities:\n",
    "                if maturity in books[index]['maturities']:\n",
    "                    new_books[index][len(maturities[maturity])\n",
    "            '''\n",
    "        return new_books\n",
    "\n",
    "    \n",
    "    def __reformat_volume(self, book):\n",
    "        new_book=[]\n",
    "        for data in book:\n",
    "            if 'categories' == data:\n",
    "                for category in self.categories:\n",
    "                    new_book.append(0)\n",
    "            elif 'description' == data:\n",
    "                for description in self.descriptions:\n",
    "                    new_book.append(0)\n",
    "            else:\n",
    "                new_book.append(book[data])\n",
    "        for category in self.categories:\n",
    "            if category in book['categories']:\n",
    "                new_book[self.categories[category]] = book['categories'].count(category)\n",
    "        for description in self.descriptions:\n",
    "            if description in book['description']:\n",
    "                new_book[self.descriptions[description]] = 1\n",
    "            \n",
    "        return new_book\n",
    "            \n",
    "\n",
    "    def __x_y_train(self, books):\n",
    "        books = deepcopy(books)\n",
    "        labels = []\n",
    "        new_books = []\n",
    "\n",
    "        for book in books:\n",
    "            item = deepcopy(book)\n",
    "            #label = np.ndarray(1)\n",
    "            #label[0] = int(item.pop(0))\n",
    "            #labels.append(label)\n",
    "            labels.append(int(item.pop(0)))\n",
    "            new_books.append(item)\n",
    "\n",
    "        return (np.array(new_books), np.array(labels))\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        '''\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Dense(units=20, input_dim=self.X_train.shape[1],\n",
    "                                     kernel_initializer='glorot_uniform',\n",
    "                                     bias_initializer='zeros',\n",
    "                                     activation='relu'))\n",
    "\n",
    "        model.add(keras.layers.Dense(units=20, input_dim=self.X_train.shape[1],\n",
    "                                     kernel_initializer='glorot_uniform',\n",
    "                                     bias_initializer='zeros',\n",
    "                                     activation='relu'))\n",
    "\n",
    "        model.add(keras.layers.Dense(units=self.y_train.shape[1], input_dim=self.X_train.shape[1],\n",
    "                                     kernel_initializer='glorot_uniform',\n",
    "                                     bias_initializer='zeros',\n",
    "                                     activation='softmax'))\n",
    "\n",
    "        sgd_optimizer = keras.optimizers.SGD(lr=0.001, decay=1e-7, momentum=0.9)\n",
    "\n",
    "        model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "        history = model.fit(self.X_train, self.y_train,\n",
    "                            batch_size=3, epochs=15, verbose=1,\n",
    "                            validation_split=0.1)\n",
    "\n",
    "        self.y_train_pred = model.predict_classes(self.X_train, verbose=0)\n",
    "\n",
    "        '''\n",
    "        \n",
    "        pipe_lr = make_pipeline(StandardScaler(),\n",
    "                                PCA(),\n",
    "                                #KNeighborsClassifier(n_neighbors=5, n_jobs=-1))\n",
    "                                LogisticRegression(random_state=1, solver='lbfgs'))\n",
    "        \n",
    "        #self.y_train = \n",
    "        pipe_lr.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.y_train_pred = pipe_lr.predict(self.X_train)\n",
    "        \n",
    "        self.__model = pipe_lr\n",
    "        \n",
    "        #pipe_sgd = make_pipeline(StandardScaler(), PCA(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "        #pipe_sgd.fit(self.X_train, self.y_train)\n",
    "        #self.y_train_pred = pipe_sgd.predict(self.X_train)\n",
    "        self.__model = pipe_lr\n",
    "    \n",
    "        \n",
    "    def feature_space(self):\n",
    "        return str(self.X_train.shape[0]) + ', ' + str(self.X_train.shape[1])\n",
    "    \n",
    "    \n",
    "    def train_acc(self):\n",
    "        return np.sum(self.y_train_pred == self.y_train, axis=0) / self.y_train.shape[0]\n",
    "    \n",
    "        \n",
    "    def __preprocess_book(self, book):\n",
    "        new_book = deepcopy(book)\n",
    "        book_data = self.__pull_books(new_book)\n",
    "        \n",
    "        if type(book_data[0]) == type(dict()):\n",
    "            return np.asarray(self.__reformat_volume(book_data[0]))\n",
    "        raise TypeError(\"Goddamn\")\n",
    "    \n",
    "    def sample_data(self):\n",
    "        return 'Original:\\n' + str(self.__book_data[0]) + '\\nPost-processed:\\n' + str(self.X_train[0]) + '\\nShape:\\n' + str(self.X_train[0].shape)\n",
    "    \n",
    "    \n",
    "    def predict(self, book=[]):\n",
    "        if book == [] or book ==\"\":\n",
    "            raise ValueError('Parameter cannot be an empty book')\n",
    "        if self.__model == None:\n",
    "            raise ValueError('Classifier needs training before predictions')\n",
    "        if type(book) != type(str()):\n",
    "            raise ValueError('Book must a valid volumeID of type \"String\"')\n",
    "\n",
    "        X_sample = self.__preprocess_book(book)\n",
    "        \n",
    "        return (self.__model.predict([X_sample]), np.max(self.__model.predict_proba([X_sample])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of volumes:\t 61\n",
      "Length of labels:\t 61\n"
     ]
    }
   ],
   "source": [
    "test_volumes = []\n",
    "test_labels = []\n",
    "\n",
    "with open('emily_books_2_tier.txt', 'r') as test_file:\n",
    "    for line in test_file:\n",
    "        items = line.split(',')\n",
    "        test_volumes.append(items[0])\n",
    "        test_labels.append(int(items[1].strip()))\n",
    "\n",
    "print('Length of volumes:\\t', len(test_volumes))\n",
    "print('Length of labels:\\t', len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = BookClassifier(test_volumes, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n",
      " {'fiction': 2, 'thrillers': 3, 'suspense': 4, 'fantasy': 5, 'contemporary': 6, 'psychological': 7, 'young adult fiction': 8, 'science fiction': 9, 'space opera': 10, 'romance': 11, 'general': 12, 'occult & supernatural': 13, 'historical': 14, 'paranormal': 15, 'fairy tales, folk tales, legends & mythology': 16, 'action & adventure': 17, 'juvenile fiction': 18, 'wizards & witches': 19, 'school & education': 20, 'boarding school & prep school': 21, 'fantasy & magic': 22, 'history': 23, 'united states': 24, 'nature': 25, 'animals': 26, 'horses': 27, 'horror': 28, 'superheroes': 29, 'gaslamp': 30, 'literary': 31, 'family life': 32, 'coming of age': 33, 'epic': 34, 'dark fantasy': 35, 'classics': 36, 'media tie-in': 37, 'mystery & detective': 38, 'humorous': 39, 'absurdist': 40, 'dragons & mythical creatures': 41, 'romantic comedy': 42, 'women': 43, 'frankenstein (fictitious character)': 44, \"frankenstein's monster (fictitious character)\": 45, 'drama': 46, 'frankenstein, victor (fictitious character)': 47, 'horror plays': 48, 'monsters': 49, 'scientists': 50, 'american': 51, 'european': 52, 'english, irish, scottish, welsh': 53, 'magical realism': 54, 'psychology': 55, 'psychopathology': 56, 'social science': 57, 'popular culture': 58, 'vampires': 59, 'social themes': 60, 'dating & sex': 61, 'paranormal, occult & supernatural': 62, 'legends, myths, fables': 63, 'love & romance': 64, 'friendship': 65, 'dating & relationships': 66, 'poetry': 67, 'ancient & classical': 68, 'dystopian': 69, 'values & virtues': 70, 'survival stories': 71, 'self-esteem & self-reliance': 72, 'time travel': 73, 'boys & men': 74, 'erotica': 75, 'death & dying': 76, 'drugs, alcohol, substance abuse': 77, 'lifestyles': 78, 'city & town life': 79, 'new experience': 80}\n",
      "Descriptions:\n",
      " {'ending': 83, 'hacked': 84, 'embarks': 85, 'crazy': 86, 'violent': 87, 'peter': 88, 'plague': 89, 'england': 90, 'just': 91, 'keen': 92, 'magicians': 93, 'insists': 94, 'memory': 95, 'quick': 96, 'competitive': 97, 'first': 98, 'freedom': 99, 'turn': 100, 'possibility': 101, 'mysteries': 102, 'encountered': 103, 'mutating': 104, 'graduation': 105, 'angeles': 106, 'philip': 107, 'sophistication': 108, 'stars': 109, 'status': 110, 'any': 111, 'award': 112, 'functioning': 113, 'asylum': 114, 'hall': 115, 'horkman': 116, 'defense': 117, 'drama': 118, 'narrated': 119, 'secrets': 120, 'bright': 121, 'headmaster': 122, 'intrigued': 123, 'panicked': 124, 'arrives': 125, 'novels': 126, 'bloods': 127, 'bustle': 128, 'shelf': 129, 'rescues': 130, 'careful': 131, 'real': 132, 'two': 133, 'inspiration': 134, 'drawn': 135, 'salander': 136, 'seen': 137, 'source': 138, 'mesmerizing': 139, 'state': 140, 'frightening': 141, 'steele': 142, 'kind': 143, 'universe': 144, 'account': 145, 'stills': 146, 'slide': 147, 'dispatched': 148, 'run': 149, 'treasure': 150, 'other': 151, 'lisa': 152, 'opens': 153, 'body': 154, 'walks': 155, 'nineteen': 156, 'space': 157, 'winner': 158, 'intolerable': 159, 'middle': 160, 'faithful': 161, 'college': 162, 'data': 163, 'sherlock': 164, 'pot': 165, 'thirst': 166, 'heroine': 167, 'ground': 168, 'tv': 169, 'locked': 170, 'dullest': 171, 'out': 172, 'superpowers': 173, 'her': 174, 'took': 175, 'abbess': 176, 'left': 177, 'crank': 178, 'library': 179, 'rowan': 180, 'judgment': 181, 'prejudice': 182, 'homage': 183, 'pursue': 184, 'frontier': 185, 'crumbling': 186, 'leading': 187, 'includes': 188, 'provide': 189, 'frequent': 190, 'tara': 191, 'did': 192, 'npr': 193, 'overgrown': 194, 'tenth': 195, 've': 196, 'joy': 197, 'falls': 198, 'stopping': 199, 'thorns': 200, 'tutor': 201, 'elaborate': 202, 'francis': 203, 'scrambling': 204, 'new': 205, 'wry': 206, 'welcome': 207, 'parallel': 208, 'alarming': 209, 'auvergne': 210, 'connection': 211, 'murders': 212, 'trustworthy': 213, 'unhappy': 214, 'passport': 215, 'verse': 216, 'destroy': 217, 'undefinable': 218, 'dead': 219, 'hardcover': 220, 'exist': 221, 'business': 222, 'sharpshooter': 223, 'writing': 224, 'greedy': 225, 'paced': 226, 'powerful': 227, 'brave': 228, 'circumstances': 229, 'aided': 230, 'malicious': 231, 'rising': 232, 'douglass': 233, 'infused': 234, 'owner': 235, 'catcher': 236, 'his': 237, 'even': 238, 'came': 239, 'testament': 240, 'set': 241, 'driving': 242, 'monster': 243, 'drug': 244, 'heads': 245, 'pi': 246, 'bizarre': 247, 'hangs': 248, 'really': 249, 'investigation': 250, 'victor': 251, 'harkness': 252, 'pandemonium': 253, 'blamed': 254, 'arresting': 255, 'outcasts': 256, 'pleasure': 257, 'competition': 258, 'zarboff': 259, 'clever': 260, 'greatly': 261, 'orphan': 262, 'name': 263, 'repelled': 264, 'sharing': 265, 'humor': 266, 'characters': 267, 'on': 268, 'daughter': 269, 'implications': 270, 'end': 271, 'abilities': 272, 'would': 273, 'meanwhile': 274, 'intriguing': 275, 'claim': 276, 'handles': 277, 'hallowe': 278, 'edgar': 279, 'proud': 280, 'bedrooms': 281, 'girlfriend': 282, 'fire': 283, 'illustrated': 284, 'collect': 285, 'relevant': 286, 'totalitarian': 287, 'allowed': 288, 'traitors': 289, 'leigh': 290, 'bubba': 291, 'world': 292, 'manipulative': 293, 'biology': 294, 'happens': 295, 'danger': 296, 'placid': 297, 'youth': 298, 'creative': 299, 'knew': 300, 'dreams': 301, 'spiritual': 302, 'makeshift': 303, 'least': 304, 'didn': 305, 'globe': 306, 'unadulterated': 307, 'exists': 308, 'woman': 309, 'relatives': 310, 'asks': 311, 'commercial': 312, 'friend': 313, 'hearts': 314, 'pain': 315, 'jealousy': 316, 'treatments': 317, 'meets': 318, 'adrenaline': 319, 'promised': 320, 'style': 321, 'heart': 322, 'extraordinary': 323, 'serpent': 324, 'explores': 325, 'journalist': 326, 'put': 327, 'adventure': 328, 'hideously': 329, 'fought': 330, 'anastasia': 331, 'diagnosis': 332, 'hidden': 333, 'spellbinding': 334, 'denied': 335, 'miss': 336, 'buried': 337, 'sequel': 338, 'masters': 339, 'butfamiliar': 340, 'than': 341, 'garcia': 342, 'money': 343, 'delilah': 344, 'disturbing': 345, 'heroes': 346, 'notions': 347, 'second': 348, 'unexpected': 349, 'web': 350, 'barely': 351, 'vernacular': 352, 'storm': 353, 'planes': 354, 'vanished': 355, 'fiercely': 356, 'reports': 357, 'so': 358, 'stand': 359, 'villain': 360, 'tearjerker': 361, 'lane': 362, 'court': 363, 'saves': 364, 'uncle': 365, 'blazing': 366, 'turner': 367, 'cast': 368, 'commanders': 369, 'authors': 370, 'dawn': 371, 'boys': 372, 'upon': 373, 'adams': 374, 'anyone': 375, 'hacker': 376, 'complete': 377, 'witches': 378, 'seemingly': 379, 'sundays': 380, 'lower': 381, 'led': 382, 'roth': 383, 'erotic': 384, 'cover': 385, 'better': 386, 'evil': 387, 'tyrant': 388, 'warlock': 389, 'victoria': 390, 'all': 391, 'picturesque': 392, 'arts': 393, 'bends': 394, 'true': 395, 'crows': 396, 'adults': 397, 'introduces': 398, 'political': 399, 'deliciously': 400, 'longer': 401, 'athlete': 402, 'flip': 403, 'soccer': 404, 'marker': 405, 'korrok': 406, 'eye': 407, 'four': 408, 'doing': 409, 'joyce': 410, 'returns': 411, 'ops': 412, 'wife': 413, 'forest': 414, 'place': 415, 'believe': 416, 'haunted': 417, 'roommates': 418, 'tattoos': 419, 'simplistic': 420, 'whole': 421, 'uglies': 422, 'beth': 423, 'horror': 424, 'comedy': 425, 'nona': 426, 'gods': 427, 'interest': 428, 'teenage': 429, 'worse': 430, 'reckless': 431, 'monthly': 432, 'teven': 433, 'father': 434, 'growing': 435, 'hurt': 436, 'foreword': 437, 'make': 438, 'chivalric': 439, 'walk': 440, 'mystery': 441, 'books': 442, 'return': 443, 'tasks': 444, 'marie': 445, 'sumptuous': 446, 'vengeance': 447, 'caring': 448, 'full': 449, 'learn': 450, 'immeasurable': 451, 'venice': 452, 'survive': 453, 'red': 454, 'stolen': 455, 'publisher': 456, 'accident': 457, 'strange': 458, 'protect': 459, 'tells': 460, 'small': 461, 'stronger': 462, 'someone': 463, 'existed': 464, 'jazz': 465, 'startled': 466, 'angels': 467, 'automatically': 468, 'gold': 469, 'free': 470, 'sophisticated': 471, 'kill': 472, 'strongly': 473, 'grew': 474, 'nature': 475, 'gin': 476, 'brain': 477, 'pets': 478, 'bone': 479, 'mystical': 480, 'reigning': 481, 'parents': 482, 'halls': 483, 'interviews': 484, 'snape': 485, 'hawksmith': 486, 'scholar': 487, 'alarm': 488, 'ringing': 489, 'force': 490, 'chronicled': 491, 'met': 492, 'running': 493, 'empathy': 494, 'genre': 495, 'fitzgerald': 496, 'attempts': 497, 'hallways': 498, 'hunger': 499, 'tense': 500, 'swiftly': 501, 'sixty': 502, 'legend': 503, 'son': 504, 'receiver': 505, 'centre': 506, 'were': 507, 'ignite': 508, 'debut': 509, 'thrill': 510, 'devastating': 511, 'firsthand': 512, 'falsely': 513, 'warriors': 514, 'illuminates': 515, 'walls': 516, 'darkness': 517, 'nicholas': 518, 'gradually': 519, 'conclusion': 520, 'conspire': 521, 'favourite': 522, 'spy': 523, 'matters': 524, 'blomqvist': 525, 'f': 526, 'certain': 527, 'south': 528, 'reimagining': 529, 'jonas': 530, 'rich': 531, 'soon': 532, 'powers': 533, 'to': 534, 'sematary': 535, 'texts': 536, 'demon': 537, 'hedge': 538, 'pudge': 539, 'shade': 540, 'waking': 541, 'planet': 542, 'rossi': 543, 'limps': 544, 'starred': 545, 'being': 546, 'martin': 547, 'relationship': 548, 'educate': 549, 'adaptation': 550, 'relishes': 551, 'oldest': 552, 'instead': 553, 'forced': 554, 'sorry': 555, 'breathtaking': 556, 'escapes': 557, 'y': 558, 'murder': 559, 'purchased': 560, 'every': 561, 'bending': 562, 'donna': 563, 'angel': 564, 'allies': 565, 'journal': 566, 'bess': 567, 'spine': 568, 'featuring': 569, 'rage': 570, 'crisis': 571, 'dreamy': 572, 'eloquent': 573, 'issues': 574, 'too': 575, 'moves': 576, 'grotesque': 577, 'twelve': 578, 'spot': 579, 'side': 580, 'varya': 581, 'coghill': 582, 'serves': 583, 'crew': 584, 'probably': 585, 'dreamed': 586, 'drink': 587, 'obscures': 588, 'spaced': 589, 'thomas': 590, 'child': 591, 'westerfeld': 592, 'shrivelled': 593, 'tend': 594, 'bond': 595, 'respond': 596, 'fraud': 597, 'less': 598, 'dysfunctional': 599, 'laini': 600, 'reviews': 601, 'runs': 602, 'day': 603, 'spreading': 604, 'tumultuous': 605, 'manipulation': 606, 'prophecies': 607, 'moral': 608, 'jon': 609, 'generation': 610, 'several': 611, 'horrific': 612, 'harry': 613, 'he': 614, 'fans': 615, 'hills': 616, 'week': 617, 'lots': 618, 'does': 619, 'myths': 620, 'held': 621, 'yorker': 622, 'secretive': 623, 'western': 624, 'rick': 625, 'competent': 626, 'contemporary': 627, 'enemies': 628, 'city': 629, 'triangle': 630, 'join': 631, 'marry': 632, 'predecessor': 633, 'tries': 634, 'silk': 635, 'management': 636, 'pedestrian': 637, 'unsentimental': 638, 'merit': 639, 'drm': 640, 'live': 641, 'photographs': 642, 'capitals': 643, 'before': 644, 'packaged': 645, 'jason': 646, 'try': 647, 'lifetime': 648, 'prize': 649, 'waits': 650, 'months': 651, 'politics': 652, 'gets': 653, 'enter': 654, 'hardly': 655, 'twenty': 656, 'dying': 657, 'mossbacher': 658, 'rings': 659, 'town': 660, 'evacuate': 661, 'head': 662, 'booklist': 663, 'saving': 664, 'introductions': 665, 'grayson': 666, 'pictures': 667, 'quality': 668, 'ghetto': 669, 'containing': 670, 'schools': 671, 'nothing': 672, 'lanahan': 673, 'anddanger': 674, 'movies': 675, 'power': 676, 'smuggler': 677, 'know': 678, 'woven': 679, 'translations': 680, 'cannot': 681, 'class': 682, 'brilliantly': 683, 'iintended': 684, 'eldest': 685, 'prime': 686, 'sunday': 687, 'twists': 688, 'surface': 689, 'terror': 690, 'll': 691, 'revealed': 692, 'fashioned': 693, 'over': 694, 'unrelenting': 695, 'documents': 696, 'challenge': 697, 'meaning': 698, 'marvel': 699, 'immediately': 700, 'bold': 701, 'content': 702, 'realizes': 703, 'kostova': 704, 'patrol': 705, 'continue': 706, 'iconic': 707, 'pilgrims': 708, 'steely': 709, 'looking': 710, 'mercy': 711, 'proves': 712, 'instant': 713, 'forever': 714, 'shop': 715, 'five': 716, 'worlds': 717, 'process': 718, 'remain': 719, 'lurks': 720, 'or': 721, 'r': 722, 'anecdotes': 723, 'grimmauld': 724, 'country': 725, 'theyset': 726, 'vivid': 727, 'lost': 728, 'captivating': 729, 'thinks': 730, 'silently': 731, 'trickster': 732, 'illegal': 733, 'settlement': 734, 'workings': 735, 'excursion': 736, 'instructs': 737, 'countries': 738, 'darker': 739, 'look': 740, 'order': 741, 'crises': 742, 'paramount': 743, 'we': 744, 'threads': 745, 'next': 746, 'holy': 747, 'subversives': 748, 'singular': 749, 'siege': 750, 'include': 751, 'marvelously': 752, 'users': 753, 'struggle': 754, 'processing': 755, 'fathom': 756, 'give': 757, 'woodley': 758, 'author': 759, 'peterand': 760, 'anticipate': 761, 'satire': 762, 'recalls': 763, 'fiction': 764, 'love': 765, 'picks': 766, 'stories': 767, 'sacrificing': 768, 'simon': 769, 'is': 770, 'fork': 771, 'ron': 772, 'there': 773, 'gone': 774, 'reserved': 775, 'developer': 776, 'continual': 777, 'malignity': 778, 'conformity': 779, 'arthur': 780, 'ward': 781, 'nightmare': 782, 'amateur': 783, 'off': 784, 'private': 785, 'much': 786, 'games': 787, 'george': 788, 'charge': 789, 'unknown': 790, 'en': 791, 'trade': 792, 'fairy': 793, 'giants': 794, 'also': 795, 'suspected': 796, 'th': 797, 'volume': 798, 'duped': 799, 'public': 800, 'known': 801, 'desperate': 802, 'perfectly': 803, 'yours': 804, 'celebrate': 805, 'sold': 806, 'pbs': 807, 'smart': 808, 'propels': 809, 'gideon': 810, '‘peculiar': 811, 'politicians': 812, 'mtv': 813, 'offered': 814, 'seductive': 815, 'dominates': 816, 'negativism': 817, 'doesn': 818, 'fray': 819, 'eleanor': 820, 'arrival': 821, 'epicenter': 822, 'behavior': 823, 'brash': 824, 'attracted': 825, 'hooked': 826, 'dimension': 827, 'building': 828, 'telling': 829, 'dazzling': 830, 'betrayal': 831, 'lessening': 832, 'conjuring': 833, 'illuminae': 834, 'wellington': 835, 'links': 836, 'achievement': 837, 'ambition': 838, 'draws': 839, 'eerie': 840, 'peregrine': 841, 'bbc': 842, 'killers': 843, 'mistakes': 844, 'sixteen': 845, 'understand': 846, 'fits': 847, 'spencer': 848, 'twilight': 849, 'goblet': 850, 'across': 851, 'happened': 852, 'names': 853, 'grown': 854, 'named': 855, 'encampment': 856, 'according': 857, 'hoax': 858, 'millions': 859, 'carrying': 860, 'keeps': 861, 'picking': 862, 'edges': 863, 'delaney': 864, 'sword': 865, 'wary': 866, 'shutting': 867, 'publication': 868, 'tournament': 869, 'fist': 870, 'changing': 871, 'saints': 872, 'starts': 873, 'where': 874, 'america': 875, 'craft': 876, 'sail': 877, 'neverwhere': 878, 'as': 879, 'island': 880, 'wizards': 881, 'sessions': 882, 'awesome': 883, 'late': 884, 'lithgow': 885, 'dangerously': 886, 'pregnant': 887, 'rekindle': 888, 'peculiar': 889, 'motorbike': 890, 'mysteriously': 891, 'glimpse': 892, 'emerge': 893, 'ocean': 894, 'percy': 895, 'been': 896, 'club': 897, 'voice': 898, 'safety': 899, 'constructed': 900, 'protégé': 901, 'defining': 902, 'young': 903, 'internationally': 904, 'dr': 905, 'racism': 906, 'glorious': 907, 'suddenly': 908, 'chaos': 909, 'offer': 910, 'brutality': 911, 'thief': 912, 'tightens': 913, 'rather': 914, 'a': 915, 'imagination': 916, 'stephen': 917, 'grievers': 918, 'right': 919, 'incapable': 920, 'fates': 921, 'arc': 922, 'duping': 923, 'chance': 924, 'miami': 925, 'perpetrating': 926, 'fraught': 927, 'discovered': 928, 'literary': 929, 'many': 930, 'himself': 931, 'mythology': 932, 'summons': 933, 'dynamic': 934, 'your': 935, 'unbroken': 936, 'childhood': 937, 'decides': 938, 'writers': 939, 'parties': 940, 'spend': 941, 'breaking': 942, 'libraryreads': 943, 'because': 944, 'revisions': 945, 'legendary': 946, 'fox': 947, 'impeccably': 948, 'have': 949, 'emotions': 950, 'fleet': 951, 'course': 952, 'cameron': 953, 'copies': 954, 'request': 955, 'reveals': 956, 'seeing': 957, 'tegan': 958, 'then': 959, 'stephenie': 960, 'national': 961, 'modern': 962, 'thin': 963, 'raining': 964, 'rare': 965, 'jackson': 966, 'harkeness': 967, 'add': 968, 'countrymen': 969, 'files': 970, 'perhaps': 971, 'weapons': 972, 'important': 973, 'interactive': 974, 'consequences': 975, 'within': 976, 'dwarfs': 977, 'surprises': 978, 'wealthy': 979, 'genuinely': 980, 'arrangement': 981, 'am': 982, 'o': 983, 'bachelor': 984, 'mad': 985, 'countless': 986, 'provoking': 987, 'fragile': 988, 'gulliver': 989, 'bardugo': 990, 'around': 991, 'far': 992, 'orders': 993, 'corridors': 994, 'praise': 995, 'rye': 996, 'moments': 997, 'release': 998, 'couldn': 999, 'various': 1000, 'exploits': 1001, 'result': 1002, 'trunk': 1003, '\\u2028': 1004, 'bodleian': 1005, 'called': 1006, 'climbers': 1007, 'clowns': 1008, 'risk': 1009, 'neil': 1010, 'scheming': 1011, 'institutionalized': 1012, 'somehow': 1013, 'forty': 1014, 'discovers': 1015, 'appetite': 1016, 'deeply': 1017, 'despite': 1018, 'winter': 1019, 'maiden': 1020, 'winning': 1021, 'mostly': 1022, 'stepson': 1023, 'trip': 1024, 'comic': 1025, 'coming': 1026, 'threatens': 1027, 'tris': 1028, 'something': 1029, 'reluctant': 1030, 'dog': 1031, 'intention': 1032, 'hailed': 1033, 'kids': 1034, 'proper': 1035, 'alone': 1036, 'interrupted': 1037, 'near': 1038, 'swore': 1039, 'daniel': 1040, 'thrilling': 1041, 'deadly': 1042, 'ageless': 1043, 'exclusive': 1044, 'those': 1045, 'six': 1046, 'language': 1047, 'mere': 1048, 'features': 1049, 'alaska': 1050, 'battles': 1051, 'romances': 1052, 'computer': 1053, 'especially': 1054, 'richard': 1055, 'naked': 1056, 'doctor': 1057, 'nora': 1058, 'happy': 1059, 'string': 1060, 'immortals': 1061, 'stage': 1062, 'belongs': 1063, 'norse': 1064, 'market': 1065, 'outlaw': 1066, 'deceitful': 1067, 'both': 1068, 'cult': 1069, 'meditation': 1070, 'rabelais': 1071, 'dudley': 1072, 'champions': 1073, 'until': 1074, 'exploring': 1075, 'native': 1076, 'that': 1077, 'louis': 1078, 'tartt': 1079, 'religion': 1080, 'director': 1081, 'making': 1082, 'conquistadors': 1083, 'nor': 1084, 'historical': 1085, 'plight': 1086, 'some': 1087, 'three': 1088, 'scholars': 1089, 'harriet': 1090, 'airing': 1091, 'tests': 1092, 'flyer': 1093, 'bloodstained': 1094, 'witch': 1095, 'forgotten': 1096, 'glimpses': 1097, 'teaching': 1098, 'disheveled': 1099, 'soul': 1100, 'embark': 1101, 'werewolf': 1102, 'dorothy': 1103, 'anansi': 1104, 'sept': 1105, 'ims': 1106, 'boyfriend': 1107, 'westerns': 1108, 'ray': 1109, 'master': 1110, 'crucial': 1111, 'spring': 1112, 'play': 1113, 'changer': 1114, 'ref': 1115, 'post': 1116, 'chu': 1117, 'talents': 1118, 'cars': 1119, 'pulls': 1120, 'autistic': 1121, 'identity': 1122, 'romance': 1123, 'warrior': 1124, 'lsd': 1125, 'jesmyn': 1126, 'star': 1127, 'influential': 1128, 'developed': 1129, 'allow': 1130, 'community': 1131, 'jobs': 1132, 'heats': 1133, 'companies': 1134, 'little': 1135, 'thrilled': 1136, 'wonder': 1137, 'since': 1138, 'successful': 1139, 'age': 1140, 'zero': 1141, 'conflict': 1142, 'title': 1143, 'lunacy': 1144, 'deduction': 1145, 'fueled': 1146, 'nightmares': 1147, 'bree': 1148, 'cliffhanger': 1149, 'arthurian': 1150, 'open': 1151, 're': 1152, 'dies': 1153, 'wednesday': 1154, 'super': 1155, 'bit': 1156, 'borders': 1157, 'boring': 1158, 'wishes': 1159, 'science': 1160, 'eclipse': 1161, 'boundary': 1162, 'threaten': 1163, 'disappears': 1164, 'cousin': 1165, 'clarke': 1166, 'happen': 1167, 'trilogy': 1168, 'rides': 1169, 'confront': 1170, 'beloved': 1171, 'freshest': 1172, 'slightly': 1173, 'neighbour': 1174, 'back': 1175, 'greater': 1176, 'novella': 1177, 'old': 1178, 'software': 1179, 'ever': 1180, 'foreign': 1181, 'works': 1182, 'candor': 1183, 'expects': 1184, 'glade': 1185, 'sky': 1186, 'heartwarming': 1187, 'pounding': 1188, 'manuscript': 1189, 'rarest': 1190, 'speak': 1191, 'highly': 1192, 'gift': 1193, 'very': 1194, 'mixed': 1195, 'ends': 1196, 'endpapers': 1197, 'formidable': 1198, 'bloody': 1199, 'psychologist': 1200, 'gillian': 1201, 'vintage': 1202, 'gardens': 1203, 'film': 1204, 'huffington': 1205, 'mix': 1206, 'intimacy': 1207, 'everdeen': 1208, 'sweet': 1209, 'encounters': 1210, 'brandishing': 1211, 'awry': 1212, 'flight': 1213, 'experiencing': 1214, 'patch': 1215, 'pirates': 1216, 'thousands': 1217, 'dossier': 1218, 'weaves': 1219, 'laboratories': 1220, 'stay': 1221, 'faith': 1222, 'creek': 1223, 'romantic': 1224, 'italy': 1225, 'tribes': 1226, 'vicious': 1227, 'walled': 1228, 'shudder': 1229, 'outside': 1230, 'natures': 1231, 'without': 1232, 'broken': 1233, 'blurring': 1234, 'vangers': 1235, 'pack': 1236, 'wondrous': 1237, 'savage': 1238, 'exceptional': 1239, 'pay': 1240, 'press': 1241, 'review': 1242, 'again': 1243, 'holly': 1244, 'shadowhunters': 1245, 'indisputable': 1246, 'rice': 1247, 'tongue': 1248, 'l': 1249, 'provided': 1250, 'hilarious': 1251, 'more': 1252, 'diagnoses': 1253, 'thrillist': 1254, 'including': 1255, 'told': 1256, 'sidekick': 1257, 'n': 1258, 'highest': 1259, 'schwab': 1260, 'school': 1261, 'finale': 1262, 'marriage': 1263, 'poetry': 1264, 'lures': 1265, 'privileged': 1266, 'twist': 1267, 'touched': 1268, 'sparkling': 1269, 'sound': 1270, 'fresh': 1271, 'loki': 1272, 'troubles': 1273, 'book': 1274, 'print': 1275, 'aboard': 1276, 'surrounded': 1277, 'classic': 1278, 'art': 1279, 'ideas': 1280, 'covered': 1281, 'maric': 1282, 'come': 1283, 'professor': 1284, 'leaders': 1285, 'masterful': 1286, 'weekly': 1287, 'represents': 1288, 'immortal': 1289, 'pantheon': 1290, 'cargo': 1291, 'game': 1292, 'pan': 1293, 'proposing': 1294, 'aside': 1295, 'gladers': 1296, 'delves': 1297, 'league': 1298, 'ability': 1299, 'girls': 1300, 'wheedling': 1301, 'hope': 1302, 'b+': 1303, 'maberry': 1304, 'grows': 1305, 'origin': 1306, 'grimace': 1307, 'tranquility': 1308, 'special': 1309, 'actions': 1310, 'empire': 1311, 'stone': 1312, 'unputdownable': 1313, 'vegas': 1314, 'molly': 1315, 'into': 1316, 'miracle': 1317, 'evocative': 1318, 'experience': 1319, 'vacation': 1320, 'plagues': 1321, 'isolation': 1322, 'stamp': 1323, 'seems': 1324, 'triwizard': 1325, 'euthanize': 1326, 'themes': 1327, 'struck': 1328, 'psychopaths': 1329, 'future': 1330, 'eater': 1331, 'relatively': 1332, 'assignment': 1333, 'dementors': 1334, 'wonderfully': 1335, 'accepts': 1336, 'worldwide': 1337, 'emails': 1338, 'leader': 1339, 'damaged': 1340, 'defined': 1341, 'net': 1342, 'inform': 1343, 'ways': 1344, 'chair': 1345, 'create': 1346, 'beginning': 1347, 'begin': 1348, 'lifestyle': 1349, 'dante': 1350, 'nest': 1351, 'david': 1352, 'stylistically': 1353, 'presents': 1354, 'adult': 1355, 'driven': 1356, 'charming': 1357, 'xxxxing': 1358, 'murderers': 1359, 'mill': 1360, 'orphanage': 1361, 'publishers': 1362, 'along': 1363, 'job': 1364, 'brothers': 1365, 'delight': 1366, 'de': 1367, 'prisons': 1368, 'everyday': 1369, 'resist': 1370, 'ou': 1371, 'cracks': 1372, 'inspired': 1373, 'hardships': 1374, 'say': 1375, 'michael': 1376, 'grisha': 1377, 'escape': 1378, 'war': 1379, 'disappeared': 1380, 'encroaching': 1381, 'john': 1382, 'coast': 1383, 'army': 1384, 'uncover': 1385, 'divide': 1386, 'inadvisable': 1387, 'lena': 1388, 'impact': 1389, 'psychic': 1390, 'scott': 1391, 'crafts': 1392, 'sudden': 1393, 'fantastically': 1394, 'detail': 1395, 'boy': 1396, 'newbery': 1397, 'sea': 1398, 'prepared': 1399, 'nationwide': 1400, 'daisy': 1401, 'track': 1402, 'suzanne': 1403, 'stripes': 1404, 'turning': 1405, 'biggest': 1406, 'bells': 1407, 'rogue': 1408, 'approaching': 1409, 'anton': 1410, 'witnesses': 1411, 'lynchian': 1412, 'savant': 1413, 'igniting': 1414, 'underground': 1415, 'narnia': 1416, 'writer': 1417, 'magazine': 1418, 'thriller': 1419, 'spends': 1420, 'comment': 1421, 'quite': 1422, 'pretty': 1423, 'resemblances': 1424, 'teen': 1425, 'classics': 1426, 'battle': 1427, 'still': 1428, 'colorless': 1429, 'evidence': 1430, 'collins': 1431, 'and': 1432, 'cadre': 1433, 'recognized': 1434, 'fault': 1435, 'rt': 1436, 'temptations': 1437, 'fear': 1438, 'passionately': 1439, 'quickly': 1440, 'precious': 1441, 'past': 1442, 'encounter': 1443, 'deeds': 1444, 'most': 1445, 'susceptibility': 1446, 'claire': 1447, 'morality': 1448, 'unofficially': 1449, 'safest': 1450, 'strictly': 1451, 'fate': 1452, 'apart': 1453, 'playing': 1454, 'handle': 1455, 'details': 1456, 'jay': 1457, 'screwed': 1458, 'responsible': 1459, 'each': 1460, 'darcy': 1461, 't': 1462, 'foe': 1463, 'hopelessly': 1464, 'adds': 1465, 'wessex': 1466, 'think': 1467, 'bonus': 1468, 'familial': 1469, 'novelistic': 1470, 'deny': 1471, 'solve': 1472, 'human': 1473, 'parody': 1474, 'introduced': 1475, 'enchanted': 1476, 'vs': 1477, 'never': 1478, 'person': 1479, 'hired': 1480, 'shows': 1481, 'visits': 1482, 'gabaldon': 1483, 'cut': 1484, 'funny': 1485, 'hear': 1486, 'herein': 1487, 'escalating': 1488, 'kami': 1489, 'v': 1490, 'diverse': 1491, 'anne': 1492, 'sparked': 1493, 'tales': 1494, 'hell': 1495, 'them': 1496, 'leaving': 1497, 'share': 1498, 'poets': 1499, 'coveted': 1500, 'prequel': 1501, 'katniss': 1502, 'loss': 1503, 'big': 1504, 'road': 1505, 'com': 1506, 'midst': 1507, 'affections': 1508, 'bradbury': 1509, 'mustang': 1510, 'hardback': 1511, 'flynn': 1512, 'test': 1513, 'eaters': 1514, 'lift': 1515, 'ruin': 1516, 'reliant': 1517, 'travellers': 1518, 'destruction': 1519, 'twisty': 1520, 'east': 1521, 'proposes': 1522, 'hostile': 1523, 'rival': 1524, 'night': 1525, 'widow': 1526, 'guess': 1527, 'preclude': 1528, 'clary': 1529, 'thoughts': 1530, 'origins': 1531, 'sensitivity': 1532, 'no': 1533, 'ebullient': 1534, 'immigrants': 1535, 'between': 1536, 'schemes': 1537, 'brilliance': 1538, 'magician': 1539, 'bleeding': 1540, 'spill': 1541, 'appeared': 1542, 'anthology': 1543, 'powered': 1544, 'fated': 1545, 'perilous': 1546, 'beneath': 1547, 'figures': 1548, 'louise': 1549, 'thread': 1550, 'unnamed': 1551, 'key': 1552, 'slowly': 1553, 'atlantic': 1554, 'pet': 1555, 'flees': 1556, 'yann': 1557, 'defying': 1558, 'clairmont': 1559, 'honed': 1560, 'poet': 1561, 'saga': 1562, 'nowhere': 1563, 'here': 1564, 'idiosyncrasies': 1565, 'now': 1566, 'slums': 1567, 'act': 1568, 'carefully': 1569, 'bella': 1570, 'why': 1571, 'miles': 1572, 'easy': 1573, 'truth': 1574, 'unbreakable': 1575, 'potential': 1576, 'security': 1577, 'gifting': 1578, 'grey': 1579, 'burke': 1580, 'close': 1581, 'octavia': 1582, 'brother': 1583, 'eternal': 1584, 'sayuri': 1585, 'members': 1586, 'quiet': 1587, 'wong': 1588, 'exception': 1589, 'girl': 1590, 'brekker': 1591, 'brought': 1592, 'grave': 1593, 'torch': 1594, 'gatlin': 1595, 'supreme': 1596, 'introduction': 1597, 'pull': 1598, 'none': 1599, 'words': 1600, 'exquisitely': 1601, 'imagery': 1602, 'famous': 1603, 'assistant': 1604, 'hobby': 1605, 'servicing': 1606, 'curious': 1607, 'deeper': 1608, 'forgiveness': 1609, 'phantasm': 1610, 'supernatural': 1611, 'immersed': 1612, 'allegories': 1613, 'possibilities': 1614, 'preview': 1615, 'timeless': 1616, 'woods': 1617, 'firing': 1618, 'antari': 1619, 'editor': 1620, 'boone': 1621, 'beautiful': 1622, 'grisly': 1623, 'blade': 1624, 'such': 1625, 'develop': 1626, 'logical': 1627, 'temperature': 1628, 'palms': 1629, 'team': 1630, 'top': 1631, 'after': 1632, 'lesson': 1633, 'about': 1634, 'unexpectedly': 1635, 'vanishing': 1636, 'doors': 1637, 'feuds': 1638, 'peckerman': 1639, 'homes': 1640, 'secluded': 1641, 'gatsby': 1642, 'confusion': 1643, 'ambassador': 1644, 'sundance': 1645, 'therapy': 1646, 'london': 1647, 'guide': 1648, 'beguiling': 1649, 'cope': 1650, 'starring': 1651, 'heartrender': 1652, 'ship': 1653, 'teenagers': 1654, 'lived': 1655, 'afoot': 1656, 'ahead': 1657, 'flying': 1658, 'challenges': 1659, 'darkest': 1660, 'notes': 1661, 'bestseller': 1662, 'mindscape': 1663, 'lu': 1664, 'ethos': 1665, 'others': 1666, 'inner': 1667, 'hollow': 1668, 'description': 1669, 'carve': 1670, 'tending': 1671, 'taylor': 1672, 'fictional': 1673, 'vampires': 1674, 'pungent': 1675, 'spirit': 1676, 'mystic': 1677, 'grief': 1678, 'ask': 1679, 'spent': 1680, 'sun': 1681, 'industry': 1682, 'long': 1683, '\\u2028\\u2028': 1684, 'tanner': 1685, 'safe': 1686, 'actually': 1687, 'ride': 1688, 'years': 1689, 'skilled': 1690, 'at': 1691, 'house': 1692, 'ezra': 1693, 'vanity': 1694, 'christopher': 1695, 'though': 1696, 'extraordinarily': 1697, 'rural': 1698, 'survival': 1699, 'church': 1700, 'birth': 1701, 'smoke': 1702, 'wardrobe': 1703, 'prison': 1704, 'nation': 1705, 'glued': 1706, 'mexican': 1707, 'revered': 1708, 'collection': 1709, 'hit': 1710, 'anticipated': 1711, 'which': 1712, 'in': 1713, 'morning': 1714, 'entered': 1715, 'throne': 1716, 'reappearance': 1717, 'mob': 1718, 'men': 1719, 'let': 1720, 'trilogies': 1721, 'student': 1722, 'beyond': 1723, 'find': 1724, 'murdered': 1725, 'reactor': 1726, 'bennet': 1727, 'hub': 1728, 'done': 1729, 'bloodhounds': 1730, 'audiences': 1731, 'mixes': 1732, 'grishaverse': 1733, 'achieve': 1734, 'our': 1735, 'yearning': 1736, 'available': 1737, 'violence': 1738, 'funeral': 1739, 'elgort': 1740, 'year': 1741, 'vengeful': 1742, 'either': 1743, 'non': 1744, 'racing': 1745, 'with': 1746, 'obstacle': 1747, 'yourselves': 1748, 'action': 1749, 'conditions': 1750, 'however': 1751, 'using': 1752, 'social': 1753, 'occasion': 1754, 'once': 1755, 'authoritative': 1756, 'assaults': 1757, 'by': 1758, 'ancestral': 1759, 'wager': 1760, 'dark': 1761, 'robs': 1762, 'point': 1763, 'own': 1764, 'capture': 1765, 'kindness': 1766, 'wrestles': 1767, 'alexander': 1768, 'couple': 1769, 'inducing': 1770, 'addictive': 1771, 'bennets': 1772, 'original': 1773, 'kady': 1774, 'invaded': 1775, 'doorbell': 1776, 'coauthor': 1777, 'themselves': 1778, 'children': 1779, 'under': 1780, 'ng': 1781, 'not': 1782, 'present': 1783, 'wealth': 1784, 'recommended': 1785, 'mature': 1786, 'from': 1787, 'centers': 1788, 'gives': 1789, 'fair': 1790, 'james': 1791, 'voldemort': 1792, 'edward': 1793, 'skull': 1794, 'dedicated': 1795, 'passion': 1796, 'failed': 1797, 'amongst': 1798, 'disgraced': 1799, 'bath': 1800, 'novel': 1801, 'swan': 1802, 'medieval': 1803, 'county': 1804, 'eight': 1805, 'wrong': 1806, 'loose': 1807, 'intense': 1808, 'warship': 1809, 'date': 1810, 'work': 1811, 'ethan': 1812, 'role': 1813, 'version': 1814, 'bravura': 1815, 'separation': 1816, 'if': 1817, 'king': 1818, 'readers': 1819, 'feels': 1820, 'vastly': 1821, 'alchemical': 1822, 'had': 1823, 'increases': 1824, 'reader': 1825, 'behind': 1826, 'together': 1827, 'narrative': 1828, 'brilliant': 1829, 'titles': 1830, 'translators': 1831, 'while': 1832, 'fourteenth': 1833, 'ribald': 1834, 'form': 1835, 'owned': 1836, 'bustling': 1837, 'lofty': 1838, 'countryside': 1839, 'leads': 1840, 'imagined': 1841, 'discovery': 1842, 'historian': 1843, 'kell': 1844, 'scientists': 1845, 'decision': 1846, 'low': 1847, 'profound': 1848, 'imminent': 1849, 'chaucer': 1850, 'ransom': 1851, 'monaghan': 1852, 'originally': 1853, 'missing': 1854, 'send': 1855, 'loved': 1856, 's': 1857, 'remarkable': 1858, 'hopes': 1859, 'neither': 1860, 'hand': 1861, 'caulfield': 1862, 'commitment': 1863, 'time': 1864, 'usa': 1865, 'henrik': 1866, 'tie': 1867, 'pages': 1868, 'runaway': 1869, 'price': 1870, 'same': 1871, 'creatures': 1872, 'do': 1873, 'gaining': 1874, 'green': 1875, 'glass': 1876, 'capitol': 1877, 'shelley': 1878, 'stillman': 1879, 'bookish': 1880, 'mistake': 1881, 'guilty': 1882, 'start': 1883, 'seventeen': 1884, 'bioware': 1885, 'illustrations': 1886, 'attraction': 1887, 'position': 1888, 'threatening': 1889, 'experimental': 1890, 'choice': 1891, 'golden': 1892, 'revenge': 1893, 'path': 1894, 'manner': 1895, 'cottage': 1896, 'sides': 1897, 'need': 1898, 'hanging': 1899, 'page': 1900, 'threat': 1901, 'standalone': 1902, 'reunite': 1903, 'agrees': 1904, 'royal': 1905, 'meyer': 1906, 'aspirations': 1907, 'prepare': 1908, 'awaits': 1909, 'fi': 1910, 'message': 1911, 'eager': 1912, 'experiences': 1913, 'nosy': 1914, 'sets': 1915, 'patient': 1916, 'pretend': 1917, 'edge': 1918, 'printed': 1919, 'christian': 1920, 'imaginative': 1921, 'when': 1922, 'hacks': 1923, 'oils': 1924, 'shared': 1925, 'onion': 1926, 'thesis': 1927, 'killed': 1928, 'fight': 1929, 'fifteen': 1930, 'divergent': 1931, 'trust': 1932, 'fifty': 1933, 'dear': 1934, 'fake': 1935, 'face': 1936, 'journeying': 1937, 'lascivious': 1938, 'should': 1939, 'continent': 1940, 'meet': 1941, 'unite': 1942, 'factions': 1943, 'rachel': 1944, 'literature': 1945, 'enslaved': 1946, 'galvanized': 1947, 'epic': 1948, 'duchannes': 1949, 'critique': 1950, 'complex': 1951, 'avengers': 1952, 'above': 1953, 'chilling': 1954, 'daring': 1955, 'remote': 1956, 'exuberant': 1957, 'reveal': 1958, 'lisbeth': 1959, 'hero': 1960, 'untested': 1961, 'criminally': 1962, 'short': 1963, 'stunningly': 1964, 'rate': 1965, 'redefined': 1966, 'number': 1967, 'lot': 1968, 'secret': 1969, 'cry': 1970, 'opera': 1971, 'purse': 1972, 'gabriella': 1973, 'take': 1974, 'started': 1975, 'follows': 1976, 'fantasy': 1977, 'crooked': 1978, 'paper': 1979, 'cusp': 1980, 'mid': 1981, 'hundred': 1982, 'light': 1983, 'falling': 1984, 'vanish': 1985, 'born': 1986, 'drawing': 1987, 'want': 1988, 'awakening': 1989, 'bratwurst': 1990, 'may': 1991, 'ruins': 1992, 'unworldly': 1993, 'although': 1994, 'lead': 1995, 'an': 1996, 'scary': 1997, 'soy': 1998, 'factories': 1999, 'began': 2000, 'coterie': 2001, 'manipulator': 2002, 'herald': 2003, 'burial': 2004, 'interpretation': 2005, 'underworld': 2006, 'fortunes': 2007, 'bare': 2008, 'intimidating': 2009, 'witty': 2010, 'talking': 2011, 'humble': 2012, 'dialogue': 2013, 'ghost': 2014, 'self': 2015, 'spread': 2016, 'tried': 2017, 'fact': 2018, 'prowess': 2019, 'traveling': 2020, 'curse': 2021, 'impossible': 2022, 'inits': 2023, 'occasionally': 2024, 'ancient': 2025, 'sister': 2026, 'dragon': 2027, 'snapped': 2028, 'waiting': 2029, 'options': 2030, 'senior': 2031, 'avatar': 2032, 'seas': 2033, 'edition': 2034, 'text': 2035, 'ultimate': 2036, 'ferelden': 2037, 'enchanting': 2038, 'terrifying': 2039, 'terrible': 2040, 'evolutionary': 2041, 'great': 2042, 'choose': 2043, 'friends': 2044, 'epoch': 2045, 'plane': 2046, 'breathlessly': 2047, 'excitement': 2048, 'i': 2049, 'demons': 2050, 'ketterdam': 2051, 'ut': 2052, 'ordinarylife': 2053, 'duology': 2054, 'nearly': 2055, 'nick': 2056, 'aslan': 2057, 'thrones': 2058, 'klara': 2059, 'nevill': 2060, 'korra': 2061, 'miller': 2062, 'door': 2063, 'palaces': 2064, 'guys': 2065, 'deserted': 2066, 'help': 2067, 'series': 2068, 'major': 2069, 'comfortable': 2070, 'officially': 2071, 'mikael': 2072, 'londons': 2073, 'moon': 2074, 'gorgeous': 2075, 'travel': 2076, 'swing': 2077, 'good': 2078, 'struggles': 2079, 'prepares': 2080, 'understatement': 2081, 'impaled': 2082, 'q': 2083, 'w': 2084, 'abandoned': 2085, 'riggs': 2086, 'their': 2087, 'but': 2088, 'memories': 2089, 'nominated': 2090, 'thing': 2091, 'incredibly': 2092, 'summer': 2093, 'whenever': 2094, 'women': 2095, 'passionate': 2096, '\\u2028\\u2028a': 2097, 'criminal': 2098, 'relish': 2099, 'crafted': 2100, 'karat': 2101, 'visual': 2102, 'unsavoury': 2103, 'bound': 2104, 'third': 2105, 'finds': 2106, 'matthew': 2107, 'undercurrent': 2108, 'grim': 2109, 'feature': 2110, 'contentment': 2111, 'riordan': 2112, 'crackling': 2113, 'singapore': 2114, 'only': 2115, 'terms': 2116, 'navigates': 2117, 'afast': 2118, 'tolkien': 2119, 'mysterious': 2120, 'malfoy': 2121, 'troubled': 2122, 'withpirates': 2123, 'thor': 2124, 'kaz': 2125, 'knows': 2126, 'older': 2127, 'elizabeth': 2128, 'foreseen': 2129, 'burn': 2130, 'joe': 2131, 'witchfinder': 2132, 'loyalty': 2133, 'who': 2134, 'rebel': 2135, 'outlander': 2136, 'window': 2137, 'pair': 2138, 'die': 2139, 'granddaughter': 2140, 'auras': 2141, 'surprising': 2142, 'this': 2143, 'insane': 2144, 'enigmatic': 2145, 'created': 2146, 'stranger': 2147, 'century': 2148, 'roaming': 2149, 'volturi': 2150, 'vanger': 2151, 'disappearance': 2152, 'clear': 2153, 'obsessed': 2154, 'airbender': 2155, 'learns': 2156, 'wand': 2157, 'abruptly': 2158, 'pennsylvania': 2159, 'giant': 2160, 'rainy': 2161, 'extremely': 2162, 'las': 2163, 'destiny': 2164, 'deal': 2165, 'treacherous': 2166, 'minds': 2167, 'choices': 2168, 'lion': 2169, 'shrinkwrapped': 2170, 'unrest': 2171, 'later': 2172, 'tendency': 2173, 'inspiring': 2174, 'she': 2175, 'destructive': 2176, 'smallest': 2177, 'ronson': 2178, 'double': 2179, 'recent': 2180, 'selection': 2181, 'can': 2182, 'halter': 2183, 'word': 2184, 'drive': 2185, 'bishop': 2186, 'ana': 2187, 'monsters': 2188, 'bears': 2189, 'eligible': 2190, 'creed': 2191, 'feel': 2192, 'printz': 2193, 'eli': 2194, 'event': 2195, 'breaks': 2196, 'significant': 2197, 'yourself': 2198, 'poignant': 2199, 'target': 2200, 'it': 2201, 'canterbury': 2202, 'francois': 2203, 'lovecraft': 2204, 'travels': 2205, 'steps': 2206, 'remembers': 2207, 'shadows': 2208, 'begins': 2209, 'bureau': 2210, 'streaming': 2211, 'street': 2212, 'lie': 2213, 'stands': 2214, 'has': 2215, 'martel': 2216, 'timeliness': 2217, 'sexy': 2218, 'lives': 2219, 'skimm': 2220, 'bedroom': 2221, 'flesh': 2222, 'previously': 2223, 'horribly': 2224, 'figure': 2225, 'unlike': 2226, 'how': 2227, 'white': 2228, 'down': 2229, 'paired': 2230, 'riveting': 2231, 'committed': 2232, 'stunning': 2233, 'published': 2234, 'up': 2235, 'people': 2236, 'question': 2237, 'secondhand': 2238, 'faces': 2239, 'applied': 2240, 'entertaining': 2241, 'remaining': 2242, 'fashions': 2243, 'consider': 2244, 'horse': 2245, 'southern': 2246, 'exactly': 2247, 'early': 2248, 'implies': 2249, 'these': 2250, 'megacorporations': 2251, 'finally': 2252, 'prodigy': 2253, 'wrenching': 2254, 'angry': 2255, 'journey': 2256, 'insight': 2257, 'university': 2258, 'fearless': 2259, 'susan': 2260, 'sacrifice': 2261, 'reservations': 2262, 'affair': 2263, 'perception': 2264, 'everything': 2265, 'celebrated': 2266, 'lord': 2267, 'culture': 2268, 'observer': 2269, 'ex': 2270, 'tale': 2271, 'eighty': 2272, 'bookshelf': 2273, 'witness': 2274, 'cullen': 2275, 'blackened': 2276, 'ten': 2277, 'wilderness': 2278, 'mary': 2279, 'april': 2280, 'veronica': 2281, 'reality': 2282, 'e': 2283, 'immortality': 2284, 'inside': 2285, 'wants': 2286, 'lit': 2287, 'loving': 2288, 'police': 2289, 'heist': 2290, 'sweeping': 2291, 'moving': 2292, 'english': 2293, 'buffalo': 2294, 'burner': 2295, 'direction': 2296, 'privet': 2297, 'corpse': 2298, 'counting': 2299, 'eradicate': 2300, 'adapted': 2301, 'primeval': 2302, 'lively': 2303, 'its': 2304, 'different': 2305, 'reason': 2306, 'austen': 2307, 'refusal': 2308, 'step': 2309, 'mind': 2310, 'suspenseful': 2311, 'tangled': 2312, 'ofthe': 2313, 'for': 2314, 'concludes': 2315, 'keep': 2316, 'rejection': 2317, 'mortgage': 2318, 'search': 2319, 'throws': 2320, 'garden': 2321, 'struggling': 2322, 'plantation': 2323, 'discover': 2324, 'looks': 2325, 'afternoon': 2326, 'york': 2327, 'always': 2328, 'hold': 2329, 'exchange': 2330, 'sometimes': 2331, 'generations': 2332, 'castaway': 2333, 'ghosts': 2334, 'tightly': 2335, 'gathering': 2336, 'instruments': 2337, 'mash': 2338, 'made': 2339, 'mayhew': 2340, 'independent': 2341, 'amazed': 2342, 'enraptured': 2343, 'changes': 2344, 'narrator': 2345, 'jeffrey': 2346, 'mistresses': 2347, 'disciplines': 2348, 'thunderstorms': 2349, 'sci': 2350, 'sisters': 2351, 'arnes': 2352, 'strong': 2353, 'accused': 2354, 'ravaged': 2355, 'entrepreneur': 2356, 'mission': 2357, 'publishing': 2358, 'belief': 2359, 'nations': 2360, 'envisioning': 2361, 'throughout': 2362, 'becomes': 2363, 'seeks': 2364, 'psychopathy': 2365, 'sitting': 2366, 'haunting': 2367, 'ordinary': 2368, 'hardest': 2369, 'was': 2370, 'longevity': 2371, 'hunting': 2372, 'able': 2373, 'zombies': 2374, 'raised': 2375, 'the': 2376, 'dives': 2377, 'knocks': 2378, 'daunted': 2379, 'defiant': 2380, 'signals': 2381, 'beauty': 2382, 'spies': 2383, 'takes': 2384, 'last': 2385, 'popular': 2386, 'development': 2387, 'tep': 2388, 'become': 2389, 'sex': 2390, 'stays': 2391, 'animal': 2392, 'magical': 2393, 'killer': 2394, 'fall': 2395, 'teach': 2396, 'arm': 2397, 'dramatically': 2398, 'ceo': 2399, 'best': 2400, 'machine': 2401, 'line': 2402, 'mark': 2403, 'blood': 2404, 'harrowing': 2405, 'buchanan': 2406, 'unto': 2407, 'ludlow': 2408, 'sane': 2409, 'you': 2410, 'through': 2411, 'odin': 2412, 'anniversary': 2413, 'mr': 2414, 'park': 2415, 'mother': 2416, 'wraith': 2417, 'magic': 2418, 'given': 2419, 'appearance': 2420, 'upheaval': 2421, 'searing': 2422, 'speck': 2423, 'overcome': 2424, 'vigor': 2425, 'nine': 2426, 'wildest': 2427, 'watches': 2428, 'events': 2429, 'obstacles': 2430, 'stop': 2431, 'sauce': 2432, 'hogwarts': 2433, 'pursuit': 2434, 'stache': 2435, 'suitable': 2436, 'victim': 2437, 'generous': 2438, 'knowledge': 2439, 'graham': 2440, 'tormented': 2441, 'enhanced': 2442, 'wondrously': 2443, 'already': 2444, 'wales': 2445, 'law': 2446, 'bookunless': 2447, 'don': 2448, 'swept': 2449, 'see': 2450, 'gothic': 2451, 'of': 2452, 'attempting': 2453, 'amc': 2454, 'lovely': 2455, 'living': 2456, 'level': 2457, 'spotlight': 2458, 'go': 2459, 'deft': 2460, 'killing': 2461, 'questions': 2462, 'speaking': 2463, 'd': 2464, 'holmes': 2465, 'party': 2466, 'against': 2467, 'malice': 2468, 'desire': 2469, 'paths': 2470, 'vampire': 2471, 'inexplicably': 2472, 'wizarding': 2473, 'seattle': 2474, 'desires': 2475, 'rogues': 2476, 'gruesome': 2477, 'save': 2478, 'means': 2479, 'tours': 2480, 'convict': 2481, 'ragnarok': 2482, 'los': 2483, 'thwaites': 2484, 'my': 2485, 'freed': 2486, 'penguin': 2487, 'demanding': 2488, 'wars': 2489, 'ansel': 2490, 'color': 2491, 'us': 2492, 'graveyards': 2493, 'teaches': 2494, 'redefines': 2495, 'remains': 2496, 'creator': 2497, 'death': 2498, 'exquisite': 2499, 'perfect': 2500, 'steals': 2501, 'frankenstein': 2502, 'invasion': 2503, 'fahrenheit': 2504, 'catch': 2505, 'shadow': 2506, 'paula': 2507, 'wine': 2508, 'touchstones': 2509, 'decades': 2510, 'win': 2511, 'loghain': 2512, 'rendition': 2513, 'captivated': 2514, 'canny': 2515, 'will': 2516, 'makes': 2517, 'international': 2518, 'articulated': 2519, 'maze': 2520, 'video': 2521, 'revis': 2522, 'black': 2523, 'geneticist': 2524, 'yet': 2525, 'genres': 2526, 'realize': 2527, 'cook': 2528, 'psychopath': 2529, 'inventive': 2530, 'remorseless': 2531, 'lonely': 2532, 'range': 2533, 'could': 2534, 'convinced': 2535, 'nobody': 2536, 'care': 2537, 'engrossing': 2538, 'entertainment': 2539, 'higher': 2540, 'maps': 2541, 'dreaming': 2542, 'co': 2543, 'forbidden': 2544, 'tour': 2545, 'twentieth': 2546, 'claims': 2547, 'simple': 2548, 'celeste': 2549, 'things': 2550, 'sneak': 2551, 'going': 2552, 'west': 2553, 'ruled': 2554, 'giver': 2555, 'injection': 2556, 'seimetz': 2557, 'cup': 2558, 'superbly': 2559, 'needs': 2560, 'selling': 2561, 'idyllic': 2562, 'farmers': 2563, 'race': 2564, 'unforgettable': 2565, 'denial': 2566, 'victorian': 2567, 'shailene': 2568, 'played': 2569, 'high': 2570, 'chicago': 2571, 'maresh': 2572, 'oxford': 2573, 'read': 2574, 'grappling': 2575, 'engaging': 2576, 'half': 2577, 'heightened': 2578, 'san': 2579, 'gathers': 2580, 'wise': 2581, 'dumbledore': 2582, 'elegantly': 2583, 'wit': 2584, 'dimartino': 2585, 'results': 2586, 'medical': 2587, 'relaxed': 2588, 'frozen': 2589, 'conceal': 2590, 'anymore': 2591, 'built': 2592, 'motion': 2593, 'note': 2594, 'turns': 2595, 'translation': 2596, 'suspicion': 2597, 'masterpiece': 2598, 'misfortune': 2599, 'anger': 2600, 'friendship': 2601, 'tastes': 2602, 'graveyard': 2603, 'working': 2604, 'insurgent': 2605, 'dystopian': 2606, 'phenomenon': 2607, 'hospital': 2608, 'evidenced': 2609, 'ventures': 2610, 'life': 2611, 'ultimately': 2612, 'culver': 2613, 'redefining': 2614, 'rights': 2615, 'remember': 2616, 'involved': 2617, 'interactions': 2618, 'changed': 2619, 'inhabited': 2620, 'knit': 2621, 'herself': 2622, 'armed': 2623, 'depth': 2624, 'official': 2625, 'obsession': 2626, 'almost': 2627, 'alive': 2628, 'learners': 2629, 'surges': 2630, 'local': 2631, 'referee': 2632, 'what': 2633, 'penetrating': 2634, 'bonds': 2635, 'hermione': 2636, 'thereader': 2637, 'wisest': 2638, 'store': 2639, 'murky': 2640, 'nearby': 2641, 'part': 2642, 'viking': 2643, 'launches': 2644, 'venture': 2645, 'installment': 2646, 'lords': 2647, 'problems': 2648, 'medal': 2649, 'carmichael': 2650, 'few': 2651, 'history': 2652, 'lies': 2653, 'deep': 2654, 'attack': 2655, 'deities': 2656, 'forces': 2657, 'wild': 2658, 'solitude': 2659, 'opportunity': 2660, 'convent': 2661, 'gritty': 2662, 'unlikely': 2663, 'days': 2664, 'ungodly': 2665, 'masterly': 2666, 'loves': 2667, 'scientist': 2668, 'today': 2669, 'riding': 2670, 'cunning': 2671, 'realms': 2672, 'zeroes': 2673, 'whose': 2674, 'plunged': 2675, 'brackston': 2676, 'hot': 2677, 'mates': 2678, 'packed': 2679, 'ribbon': 2680, 'ago': 2681, 'exploration': 2682, 'quest': 2683, 'story': 2684, 'opposite': 2685, 'warnings': 2686, 'watching': 2687, 'strength': 2688, 'brace': 2689, 'immerses': 2690, 'ho': 2691, 'survives': 2692, 'sign': 2693, 'control': 2694, 'tragedy': 2695, 'haddon': 2696, 'beach': 2697, 'thorough': 2698, 'hallmarks': 2699, 'strife': 2700, 'willing': 2701, 'm': 2702, 'elizabethan': 2703, 'stops': 2704, 'deepest': 2705, 'bill': 2706, 'ew': 2707, 'him': 2708, 'tingling': 2709, 'prep': 2710, 'kirkus': 2711, 'show': 2712, 'adamson': 2713, 'kingdom': 2714, 'continues': 2715, 'offers': 2716, 'amorality': 2717, 'be': 2718, 'depths': 2719, 'creating': 2720, 'talked': 2721, 'courtly': 2722, 'voices': 2723, 'group': 2724, 'killings': 2725, 'j': 2726, 'research': 2727, 'brisk': 2728, 'kier': 2729, 'foreboding': 2730, 'bestselling': 2731, 'transcending': 2732, 'wherever': 2733, 'pose': 2734, 'million': 2735, 'adolescents': 2736, 'change': 2737, 'gaiman': 2738, 'admonishments': 2739, 'pursued': 2740, 'career': 2741, 'irrevocably': 2742, 'home': 2743, 'sinister': 2744, 'brings': 2745, 'breathe': 2746, 'urgency': 2747, 'allegiances': 2748, 'quintessential': 2749, 'queen': 2750, 'unrivalled': 2751, 'professional': 2752, 'sparks': 2753, 'libraries': 2754, 'mortal': 2755, 'gem': 2756, 'knowing': 2757, 'leave': 2758, 'k': 2759, 'distinguished': 2760, 'admits': 2761, 'global': 2762, 'demands': 2763, 'noose': 2764, 'x': 2765, 'movie': 2766, 'tradition': 2767, 'tree': 2768, 'like': 2769, 'heartbeat': 2770, 'probes': 2771, 'compulsion': 2772, 'revolutionaries': 2773, 'shocked': 2774, 'hands': 2775, 'unique': 2776, 'bard': 2777, 'ideal': 2778, 'physical': 2779, 'updated': 2780, 'shades': 2781, 'ashmole': 2782, 'gifted': 2783, 'saved': 2784, 'astonishing': 2785, 'suspense': 2786, 'sharpness': 2787, 'they': 2788, 'discoverrichly': 2789, 'air': 2790, 'jonathan': 2791, 'inclined': 2792, 'promises': 2793, 'diana': 2794, 'iii': 2795, 'forks': 2796, 'envy': 2797, 'final': 2798, 'sensual': 2799, 'fears': 2800, 'amy': 2801, 'farce': 2802, 'sub': 2803, 'deborah': 2804, 'hannett': 2805, 'enemy': 2806, 'adventurers': 2807, 'guardian': 2808, 'intended': 2809, 'permuted': 2810, 'dragons': 2811, 'bodyguard': 2812, 'reading': 2813, 'truculent': 2814, 'lovers': 2815, 'archnemeses': 2816, 'skill': 2817, 'clutches': 2818, 'sultry': 2819, 'holden': 2820, 'thrills': 2821, 'deepens': 2822, 'searching': 2823, 'finalist': 2824, 'way': 2825, 'one': 2826, 'gripping': 2827, 'enough': 2828, 'personal': 2829, 'understanding': 2830, 'composition': 2831, 'washington': 2832, 'overall': 2833, 'levels': 2834, 'serial': 2835, 'heartbreak': 2836, 'crackles': 2837, 'arrogant': 2838, 'collide': 2839, 'fitzwilliam': 2840, 'grownup': 2841, 'aveyard': 2842, 'wate': 2843, 'japan': 2844, 'interview': 2845, 'centuries': 2846, 'unsurpassable': 2847, 'fantastical': 2848, 'critics': 2849, 'another': 2850, 'illusion': 2851, 'swift': 2852, 'might': 2853, 'geisha': 2854, 'delusional': 2855, 'comes': 2856, 'wolves': 2857, 'potter': 2858, 'courage': 2859, 'thought': 2860, 'utterly': 2861, 'american': 2862, 'among': 2863, 'everyone': 2864, 'me': 2865, 'character': 2866, 'determined': 2867, 'teens': 2868, 'passed': 2869, 'squad': 2870, 'boarding': 2871, 'madness': 2872, 'trucks': 2873, 'coscarelli': 2874, 'well': 2875, 'picture': 2876, 'man': 2877, 'awareness': 2878, 'tell': 2879, 'wide': 2880, 'boiling': 2881, 'map': 2882, 'christmas': 2883, 'dissolution': 2884, 'jacob': 2885, 'photography': 2886, 'sidewalk': 2887, 'truly': 2888, 'fascinating': 2889, 'noted': 2890, 'souls': 2891, 'immortalists': 2892, 'land': 2893, 'emperor': 2894, 'anything': 2895, 'bones': 2896, 'regime': 2897, 'maine': 2898, 'poverty': 2899, 'burning': 2900, 'bewitching': 2901, 'heroism': 2902, 'temptation': 2903, 'following': 2904, 'burns': 2905, 'crave': 2906, 'fun': 2907, 'infamous': 2908, 'harmless': 2909, 'rescued': 2910, 'gil': 2911, 'away': 2912, 'betrayed': 2913, 'itself': 2914, 'ai': 2915, 'prose': 2916, 'faithless': 2917, 'fully': 2918, 'clan': 2919, 'delve': 2920, 'herbs': 2921, 'leaves': 2922, 'quarantined': 2923, 'opulent': 2924, 'female': 2925, 'pulled': 2926, 'family': 2927, 'payment': 2928, 'swamps': 2929, 'california': 2930, 'horses': 2931, 'creature': 2932, 'steal': 2933, 'getting': 2934, 'knight': 2935, 'goes': 2936, 'firemen': 2937, 'dangerous': 2938, 'acclaimed': 2939, 'are': 2940, 'initially': 2941, 'digital': 2942, 'headed': 2943, 'tattoed': 2944, 'brenton': 2945, 'lavish': 2946, 'climb': 2947, 'envisions': 2948, 'descendant': 2949, 'haughty': 2950, 'starting': 2951, 'emotional': 2952, 'effect': 2953, 'theo': 2954, 'rowling': 2955, 'palace': 2956, 'hackers': 2957, 'times': 2958, 'academic': 2959, 'hungry': 2960, 'midnight': 2961, 'investigate': 2962, 'must': 2963, 'treachery': 2964, 'francisco': 2965, 'genesis': 2966, 'eyes': 2967, 'compelling': 2968, 'soldiers': 2969}\n",
      "\n",
      "\n",
      "\n",
      "Example Data:\n",
      " Original:\n",
      "{'user_rating': 1, 'page_count': 352, 'categories': ['fiction', 'thrillers', 'suspense', 'fantasy', 'contemporary', 'psychological'], 'average_rating': 4.0, 'ratings_count': 34, 'description': {'its', 'unsentimental', 'truth', 'peter', 'england', 'just', 'mind', 'understanding', 'brother', 'for', 'realms', 'us', 'girl', 'and', 'twenty', 'world', 'rings', 'older', 'town', 'parents', 'story', 'dreams', 'award', 'looks', 'alarm', 'ringing', 'exploring', 'that', 'disappearance', 'will', 'real', 'some', 'heart', 'where', 'doorbell', 'challenge', 'mesmerizing', 'as', 'kind', 'not', 'disheveled', 'peculiar', 'from', 'centers', 'been', 'later', 'she', 'looking', 'master', 'was', 'after', 'young', 'than', 'novel', 'suddenly', 'the', 'christmas', 'a', 'barely', 'her', 'vanished', 'fact', 'magical', 'miracle', 'it', 'denial', 'home', 'martin', 'lived', 'title', 'tara', 'stands', 'have', 'author', 'then', 'bit', 's', 'every', 'bending', 'new', 'up', 'is', 'add', 'there', 'gone', 'slightly', 'years', 'implies', 'graham', 'at', 'joyce', 'unique', 'exist', 'journey', 'around', 'between', 'of', 'unknown', 'fairy', 'perception', 'acclaimed', 'disappeared', 'good', 'are', 'tale', 'known', 'very', 'sudden', 'but', 'incredibly', 'in', 'day', 'winning', 'reality', 'return', 'bells', 'does', 'when', 'grim', 'english', 'small', 'on', 'our'}}\n",
      "Post-processed:\n",
      "[352.   1.   1. ...   0.   0.   0.]\n",
      "Shape:\n",
      "(2969,)\n"
     ]
    }
   ],
   "source": [
    "backup_model = deepcopy(test_model)\n",
    "backup_model.fit()\n",
    "print('Categories:\\n', backup_model.categories)\n",
    "print('Descriptions:\\n', backup_model.descriptions)\n",
    "print('\\n\\n')\n",
    "print('Example Data:\\n', backup_model.sample_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backup_model.train_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.7039178837030692)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TortillaCurtain = 'yYPnwMpmeT4C'\n",
    "backup_model.predict(TortillaCurtain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.7288035202390153)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nineteeneightyfour = 'VO8nDwAAQBAJ'\n",
    "backup_model.predict(nineteeneightyfour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.717484457486852)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClockworkAngel = 'rv5wCgAAQBAJ'\n",
    "backup_model.predict(ClockworkAngel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.5694195130714249)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LookingForAlaska = '5v1NBhR1W88C'\n",
    "backup_model.predict(LookingForAlaska)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.9906652542141093)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grey = 'zS3ACQAAQBAJ'\n",
    "backup_model.predict(Grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.9692234109118062)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BabyTeeth = 'Vuw7DwAAQBAJ'\n",
    "backup_model.predict(BabyTeeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.9396098733759153)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AmericanAssassin = 'kqgxDwAAQBAJ'\n",
    "backup_model.predict(AmericanAssassin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), 0.9430484876548318)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TheStand = 'UbfnTcmkaKkC'\n",
    "backup_model.predict(TheStand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
