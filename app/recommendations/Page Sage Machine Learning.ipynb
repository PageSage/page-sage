{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Page Sage\n",
    "\n",
    "This notebook should serve as a tutorial and explanatory process for the Page Sage recommendation algorithm.\n",
    "\n",
    "First, let's create some preprocessors for the data since we know what format to expect them.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def text_preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', ' ', text)\n",
    "    text_split = text.split('\\\\')\n",
    "    return ''.join(text_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text preprocessor removes the html code and backslashes from the inputted text.  The description tends to have html information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_preprocessor(categories):\n",
    "    if type(categories) != type(list()):\n",
    "        return categories\n",
    "    cats = []\n",
    "    for category in categories:\n",
    "        cat_split = category.split('/')\n",
    "        for cat in cat_split:\n",
    "            if cat.strip(' ') not in cats:\n",
    "                cats.append(cat.strip(' '))\n",
    "\n",
    "    return cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category preprocessor removes the '/' character to altogether remove the sub category listings.\n",
    "\n",
    "-----\n",
    "\n",
    "Now that the preprocessors are done, we can write the method to do our `GET` requests to the Google Books Search API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def pull_books(book_list):\n",
    "    book_data = []\n",
    "    search_key = str(os.environ.get('SEARCH_KEY'))\n",
    "    baseURL = 'https://www.googleapis.com/books/v1/volumes/'\n",
    "    endURL = '?key=' + search_key\n",
    "    \n",
    "    headers = {'Accept': 'application/json'}\n",
    "    \n",
    "    for volume in book_list:\n",
    "        url = baseURL + volume['id'] + endURL\n",
    "        book_info = requests.get(url, params=headers).json()\n",
    "        new_book = {}\n",
    "        \n",
    "        new_book['rating'] = volume['rating']\n",
    "        \n",
    "        try:\n",
    "            page_count = int(book_info['volumeInfo']['pageCount'])\n",
    "        except (KeyError):\n",
    "            page_count = 100 \n",
    "\n",
    "        try:\n",
    "            categories = category_preprocessor(book_info['volumeInfo']['categories'])\n",
    "        except (KeyError):\n",
    "            categories = category_preprocessor(['Fiction'])\n",
    "\n",
    "        try:\n",
    "            average_rating = float(book_info['volumeInfo']['averageRating'])\n",
    "        except (KeyError):\n",
    "            average_rating = float(3.5)\n",
    "\n",
    "        try:\n",
    "            ratings_count = book_info['volumeInfo']['ratingsCount']\n",
    "        except (KeyError):\n",
    "            ratings_count = float(0)\n",
    "\n",
    "        try:\n",
    "            maturity_rating = book_info['volumeInfo']['maturityRating']\n",
    "        except (KeyError):\n",
    "            maturity_rating = 'NOT_MATURE'\n",
    "\n",
    "        try:\n",
    "            description = text_preprocessor(book_info['volumeInfo']['description'])\n",
    "        except (KeyError):\n",
    "            cats = \"\"\n",
    "            for cat in categories:\n",
    "                cats += cat + \" \" \n",
    "            description = text_preprocessor(book_info['volumeInfo']['title'] + \" \" + cats)\n",
    "\n",
    "        book_data.append({\n",
    "            'rating'         : volume['rating'],\n",
    "            'page_count'     : page_count,\n",
    "            'categories'     : categories,\n",
    "            'average_rating' : average_rating,\n",
    "            'ratings_count'  : ratings_count,\n",
    "            'maturity_rating': maturity_rating,\n",
    "            'description'    : description\n",
    "        })  \n",
    "    \n",
    "    return book_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method has a bunch of try/except statements.  This is because the Google Books Search API sometimes does not return information in its `volume` requests (even though the information exists in the general `list` requests).  Some defaults were picked to fill in some of the data, with average (or most common) values being chosen for each default.\n",
    "\n",
    "-----\n",
    "\n",
    "Now, we read in a list of books from the following file:\n",
    "\n",
    "`emily_books_2_tier.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 books were read in\n"
     ]
    }
   ],
   "source": [
    "def read_book_list(filename):\n",
    "    volumes = []\n",
    "    with open(filename, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            volume = line.split(',')\n",
    "            volumes.append({'id': volume[0], 'rating': int(volume[1].strip())})\n",
    "    return volumes\n",
    "\n",
    "book_list = read_book_list('emily_books_2_tier.txt')\n",
    "\n",
    "print('%i books were read in' % len(book_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "Next we make the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = pull_books(book_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's take a look at what the data looks like now by viewing the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\t:\t1\n",
      "page_count\t:\t352\n",
      "categories\t:\t['Fiction', 'Thrillers', 'Suspense', 'Fantasy', 'Contemporary', 'Psychological']\n",
      "average_rating\t:\t4.0\n",
      "ratings_count\t:\t34\n",
      "maturity_rating\t:\tNOT_MATURE\n",
      "description\t:\t Acclaimed author Graham Joyce's mesmerizing new novel centers around the disappearance of a young girl from a small town in the heart of England. Her sudden return twenty years later, and the mind-bending tale of where she's been, will challenge our very perception of truth.    For twenty years after Tara Martin disappeared from her small English town, her parents and her brother, Peter, have lived in denial of the grim fact that she was gone for good. And then suddenly, on Christmas Day, the doorbell rings at her parents' home and there, disheveled and slightly peculiar looking, Tara stands. It's a miracle, but alarm bells are ringing for Peter. Tara's story just does not add up. And, incredibly, she barely looks a day older than when she vanished.    Award-winning author Graham Joyce is a master of exploring new realms of understanding that exist between dreams and reality, between the known and unknown.  Some Kind of Fairy Tale  is a unique journey every bit as magical as its title implies, and as real and unsentimental as the world around us.\n"
     ]
    }
   ],
   "source": [
    "for book_info in book_data[0]:\n",
    "    print('%s\\t:\\t%s' % (book_info, book_data[0][book_info]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Let's also get a read on the review balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 positive reviews in this dataset\n",
      "There are 29 negative reviews in this dataset\n",
      "(or)\n",
      "There is a 52/47 balance between positive and negative reviews\n"
     ]
    }
   ],
   "source": [
    "positive = 0\n",
    "negative = 0\n",
    "\n",
    "for book_info in book_data:\n",
    "    if book_info['rating'] == 1:\n",
    "        positive += 1\n",
    "    else:\n",
    "        negative += 1\n",
    "\n",
    "review_share = lambda x: 100*x/len(book_data)\n",
    "    \n",
    "print('There are %i positive reviews in this dataset' % (positive))\n",
    "print('There are %i negative reviews in this dataset' % (negative))\n",
    "print('(or)')\n",
    "print('There is a %i/%i balance between positive and negative reviews' % (review_share(positive), \\\n",
    "                                                                          review_share(negative)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "That's a nice, pretty even balance.   Let's move on to training.\n",
    "\n",
    "To train this dataset, we will have to do a fair amount one-hot encoding, as well as creating a bag of words for the descriptions.\n",
    "\n",
    "Since our data is formatted in a somewhat strange way, we'll have to do some one-hot encoding by hand.\n",
    "\n",
    "Let's first make the data a bit more  processable, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new book list is 61 elements long.\n",
      "\n",
      "1\n",
      "352\n",
      "['Fiction', 'Thrillers', 'Suspense', 'Fantasy', 'Contemporary', 'Psychological']\n",
      "4.0\n",
      "34\n",
      "NOT_MATURE\n",
      " Acclaimed author Graham Joyce's mesmerizing new novel centers around the disappearance of a young girl from a small town in the heart of England. Her sudden return twenty years later, and the mind-bending tale of where she's been, will challenge our very perception of truth.    For twenty years after Tara Martin disappeared from her small English town, her parents and her brother, Peter, have lived in denial of the grim fact that she was gone for good. And then suddenly, on Christmas Day, the doorbell rings at her parents' home and there, disheveled and slightly peculiar looking, Tara stands. It's a miracle, but alarm bells are ringing for Peter. Tara's story just does not add up. And, incredibly, she barely looks a day older than when she vanished.    Award-winning author Graham Joyce is a master of exploring new realms of understanding that exist between dreams and reality, between the known and unknown.  Some Kind of Fairy Tale  is a unique journey every bit as magical as its title implies, and as real and unsentimental as the world around us.\n"
     ]
    }
   ],
   "source": [
    "def make_processable(book_data):\n",
    "    books = []\n",
    "    for book_info in book_data:\n",
    "        book = []\n",
    "        for key in book_info:\n",
    "            book.append(book_info[key])\n",
    "        books.append(book)\n",
    "    return books\n",
    "\n",
    "books = make_processable(book_data)\n",
    "\n",
    "print('The new book list is %i elements long.\\n' % (len(books)))\n",
    "\n",
    "for book_info in books[0]:\n",
    "    print(book_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That makes it a little bit easier to see what needs to be preprocessed.\n",
    "\n",
    "The first problem is processing the 3 item (categories).  Let's work on one-hot encoding that.\n",
    "\n",
    "First, we'll gather all the different possibilities, then we'll transform them into one-hots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 categories for this user.\n",
      "\n",
      "The categories are:\n",
      " ['fiction', 'thrillers', 'suspense', 'fantasy', 'contemporary', 'psychological', 'young adult fiction', 'science fiction', 'space opera', 'romance', 'general', 'occult & supernatural', 'historical', 'paranormal', 'fairy tales, folk tales, legends & mythology', 'action & adventure', 'juvenile fiction', 'wizards & witches', 'school & education', 'boarding school & prep school', 'fantasy & magic', 'history', 'united states', 'nature', 'animals', 'horses', 'horror', 'superheroes', 'gaslamp', 'literary', 'family life', 'coming of age', 'epic', 'dark fantasy', 'classics', 'media tie-in', 'mystery & detective', 'humorous', 'absurdist', 'dragons & mythical creatures', 'romantic comedy', 'women', 'frankenstein (fictitious character)', \"frankenstein's monster (fictitious character)\", 'drama', 'frankenstein, victor (fictitious character)', 'horror plays', 'monsters', 'scientists', 'american', 'european', 'english, irish, scottish, welsh', 'magical realism', 'psychology', 'psychopathology', 'social science', 'popular culture', 'vampires', 'social themes', 'dating & sex', 'paranormal, occult & supernatural', 'legends, myths, fables', 'love & romance', 'friendship', 'dating & relationships', 'poetry', 'ancient & classical', 'dystopian', 'values & virtues', 'survival stories', 'self-esteem & self-reliance', 'time travel', 'boys & men', 'erotica', 'death & dying', 'drugs, alcohol, substance abuse', 'lifestyles', 'city & town life', 'new experience']\n"
     ]
    }
   ],
   "source": [
    "def gather_categories(books):\n",
    "    categories = []\n",
    "    for book in books:\n",
    "        for category in book[2]:\n",
    "            if category.lower() not in categories:\n",
    "                categories.append(category.lower())\n",
    "    return categories\n",
    "\n",
    "user_categories = gather_categories(books)\n",
    "\n",
    "print('There are %i categories for this user.\\n' % (len(user_categories)))\n",
    "print('The categories are:\\n', user_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Since there are 81 categories, we need an 81 bit binary string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions for each category:\n",
      "fiction  :  2\n",
      "thrillers  :  3\n",
      "suspense  :  4\n",
      "fantasy  :  5\n",
      "contemporary  :  6\n",
      "psychological  :  7\n",
      "young adult fiction  :  8\n",
      "science fiction  :  9\n",
      "space opera  :  10\n",
      "romance  :  11\n",
      "general  :  12\n",
      "occult & supernatural  :  13\n",
      "historical  :  14\n",
      "paranormal  :  15\n",
      "fairy tales, folk tales, legends & mythology  :  16\n",
      "action & adventure  :  17\n",
      "juvenile fiction  :  18\n",
      "wizards & witches  :  19\n",
      "school & education  :  20\n",
      "boarding school & prep school  :  21\n",
      "fantasy & magic  :  22\n",
      "history  :  23\n",
      "united states  :  24\n",
      "nature  :  25\n",
      "animals  :  26\n",
      "horses  :  27\n",
      "horror  :  28\n",
      "superheroes  :  29\n",
      "gaslamp  :  30\n",
      "literary  :  31\n",
      "family life  :  32\n",
      "coming of age  :  33\n",
      "epic  :  34\n",
      "dark fantasy  :  35\n",
      "classics  :  36\n",
      "media tie-in  :  37\n",
      "mystery & detective  :  38\n",
      "humorous  :  39\n",
      "absurdist  :  40\n",
      "dragons & mythical creatures  :  41\n",
      "romantic comedy  :  42\n",
      "women  :  43\n",
      "frankenstein (fictitious character)  :  44\n",
      "frankenstein's monster (fictitious character)  :  45\n",
      "drama  :  46\n",
      "frankenstein, victor (fictitious character)  :  47\n",
      "horror plays  :  48\n",
      "monsters  :  49\n",
      "scientists  :  50\n",
      "american  :  51\n",
      "european  :  52\n",
      "english, irish, scottish, welsh  :  53\n",
      "magical realism  :  54\n",
      "psychology  :  55\n",
      "psychopathology  :  56\n",
      "social science  :  57\n",
      "popular culture  :  58\n",
      "vampires  :  59\n",
      "social themes  :  60\n",
      "dating & sex  :  61\n",
      "paranormal, occult & supernatural  :  62\n",
      "legends, myths, fables  :  63\n",
      "love & romance  :  64\n",
      "friendship  :  65\n",
      "dating & relationships  :  66\n",
      "poetry  :  67\n",
      "ancient & classical  :  68\n",
      "dystopian  :  69\n",
      "values & virtues  :  70\n",
      "survival stories  :  71\n",
      "self-esteem & self-reliance  :  72\n",
      "time travel  :  73\n",
      "boys & men  :  74\n",
      "erotica  :  75\n",
      "death & dying  :  76\n",
      "drugs, alcohol, substance abuse  :  77\n",
      "lifestyles  :  78\n",
      "city & town life  :  79\n",
      "new experience  :  80\n"
     ]
    }
   ],
   "source": [
    "def generate_category_one_hot(categories):\n",
    "    offset = 2\n",
    "    cat_dict = dict()\n",
    "    for category in categories:\n",
    "        cat_dict[category] = offset\n",
    "        offset += 1\n",
    "    return cat_dict\n",
    "    \n",
    "categories = generate_category_one_hot(user_categories)\n",
    "\n",
    "print('Positions for each category:')\n",
    "for category in categories:\n",
    "    print('%s  :  %s' %  (category, categories[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Each category has been given a numerical value that acts as the index to where it should be a 1.\n",
    "\n",
    "Now, to reformat the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the reformatted books is 61\n",
      "The length of a new book in the categories is 85\n"
     ]
    }
   ],
   "source": [
    "def reformat_categories(books_data):\n",
    "    reformatted_books_data = []\n",
    "    for book in books_data:\n",
    "        new_book = []\n",
    "        for info in book:\n",
    "            if type(info) == type(list()):\n",
    "                for i in range(len(categories)):\n",
    "                    new_book.append(0)\n",
    "            else:\n",
    "                new_book.append(info)\n",
    "        reformatted_books_data.append(new_book)\n",
    "    return reformatted_books_data\n",
    "        \n",
    "new_books  = reformat_categories(books)\n",
    "\n",
    "print('The length of the reformatted books is %i' % (len(new_books)))\n",
    "print('The length of a new book in the categories is %i' % (len(new_books[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Now let's one hot encode categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Book format:\n",
      " [1, 352, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4.0, 34, 'NOT_MATURE', \" Acclaimed author Graham Joyce's mesmerizing new novel centers around the disappearance of a young girl from a small town in the heart of England. Her sudden return twenty years later, and the mind-bending tale of where she's been, will challenge our very perception of truth.    For twenty years after Tara Martin disappeared from her small English town, her parents and her brother, Peter, have lived in denial of the grim fact that she was gone for good. And then suddenly, on Christmas Day, the doorbell rings at her parents' home and there, disheveled and slightly peculiar looking, Tara stands. It's a miracle, but alarm bells are ringing for Peter. Tara's story just does not add up. And, incredibly, she barely looks a day older than when she vanished. \\xa0  Award-winning author Graham Joyce is a master of exploring new realms of understanding that exist between dreams and reality, between the known and unknown.  Some Kind of Fairy Tale  is a unique journey every bit as magical as its title implies, and as real and unsentimental as the world around us.\"]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def one_hot_categories(old_books, new_books, categories):\n",
    "    new_books = deepcopy(new_books)\n",
    "    for index, old_book in enumerate(old_books):\n",
    "        old_categories = old_book[2]\n",
    "        \n",
    "        for category in old_categories:\n",
    "            new_books[index][categories[category.lower()]] = 1\n",
    "    return new_books\n",
    "\n",
    "new_books = one_hot_categories(books, new_books, categories)\n",
    "\n",
    "print('New Book format:\\n', new_books[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "That adds a lot of dimensions, but it sure looks a lot better for processing!\n",
    "\n",
    "Let's now do the same process for the maturity ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_mature']\n"
     ]
    }
   ],
   "source": [
    "def gather_maturities(books):\n",
    "    maturities = []\n",
    "    for book in books:\n",
    "        if book[83].lower() not in maturities:\n",
    "            maturities.append(book[83].lower())\n",
    "    return maturities\n",
    "\n",
    "maturity_list = gather_maturities(new_books)\n",
    "print(maturity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Luckily, we only have one maturity level, but let's still encode it for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions for each maturity:\n",
      " {'not_mature': 83}\n"
     ]
    }
   ],
   "source": [
    "def generate_maturity_one_hot(maturities):\n",
    "    offset = 83\n",
    "    mat_dict = dict()\n",
    "    for maturity in maturities:\n",
    "        mat_dict[maturity] = offset\n",
    "        offset += 1\n",
    "    return mat_dict\n",
    "\n",
    "maturities = generate_maturity_one_hot(maturity_list)\n",
    "\n",
    "print('Positions for each maturity:\\n', maturities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the reformatted books is 61\n",
      "The length of a new book with the reformat is 85\n"
     ]
    }
   ],
   "source": [
    "def reformat_maturities(books_data):\n",
    "    reformatted_books_data = []\n",
    "    for book in books_data:\n",
    "        new_book = []\n",
    "        for index, info in enumerate(book):\n",
    "            if index == 83:\n",
    "                for i in range(len(maturities)):\n",
    "                    new_book.append(0)\n",
    "            else:\n",
    "                new_book.append(info)\n",
    "        reformatted_books_data.append(new_book)\n",
    "    return reformatted_books_data\n",
    "\n",
    "new_books = reformat_maturities(new_books)\n",
    "print('The length of the reformatted books is %i' % (len(new_books)))\n",
    "print('The length of a new book with the reformat is %i' % (len(new_books[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Now let's add the 1s in the appropriate spots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book data format is:\n",
      " [1, 352, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4.0, 34, 1, \" Acclaimed author Graham Joyce's mesmerizing new novel centers around the disappearance of a young girl from a small town in the heart of England. Her sudden return twenty years later, and the mind-bending tale of where she's been, will challenge our very perception of truth.    For twenty years after Tara Martin disappeared from her small English town, her parents and her brother, Peter, have lived in denial of the grim fact that she was gone for good. And then suddenly, on Christmas Day, the doorbell rings at her parents' home and there, disheveled and slightly peculiar looking, Tara stands. It's a miracle, but alarm bells are ringing for Peter. Tara's story just does not add up. And, incredibly, she barely looks a day older than when she vanished. \\xa0  Award-winning author Graham Joyce is a master of exploring new realms of understanding that exist between dreams and reality, between the known and unknown.  Some Kind of Fairy Tale  is a unique journey every bit as magical as its title implies, and as real and unsentimental as the world around us.\"]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_maturities(old_books, new_books, maturities):\n",
    "    new_books = deepcopy(new_books)\n",
    "    for index, old_book in enumerate(old_books):\n",
    "        new_books[index][maturities[old_book[5].lower()]] = 1\n",
    "    return new_books\n",
    "\n",
    "new_books = one_hot_maturities(books, new_books, maturities)\n",
    "\n",
    "print('The book data format is:\\n', new_books[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Perfect!  Now we need to preprocess the last string.\n",
    "\n",
    "For this we will do a bag of words for all of the data in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/peter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package names to /Users/peter/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10011 words in the Porter Stemmer tokenized text w/o other preprocessing\n",
      "There are 2466 words in the Porter Stemmer tokenized text w/ other preprocessing\n",
      "There are 2357 words in the Porter Stemmer tokenized text after removing stop words\n",
      "There are 2183 words in the Porter Stemmer tokenized text after removing names\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "success = nltk.download('stopwords')\n",
    "success = nltk.download('names')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import names\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "name = names.words()\n",
    "name = [n.lower() for n in name]\n",
    "\n",
    "def collect_and_trim_punctuation(books):\n",
    "    sentences = \"\"\n",
    "    for book in books:\n",
    "        text = book[len(book)-1]\n",
    "        text = re.sub(',', ' ', text)\n",
    "        text = re.sub('\\\\xa0', ' ', text)\n",
    "        text = re.sub('★', ' ', text)\n",
    "        text = re.sub('-', ' ', text)\n",
    "        text = re.sub('[0-9]', ' ', text)\n",
    "        text = re.sub('\"', ' ', text)\n",
    "        text = re.sub(\"'\", ' ', text)\n",
    "        sentences += text.lower() + \" \"\n",
    "    return sentences\n",
    "\n",
    "def porter_tokenizer(text):\n",
    "    porter = [PorterStemmer().stem(word) for word in text.split()]\n",
    "    new_porter = set()\n",
    "    for p in porter:\n",
    "        if '(' in p or ')' in p:\n",
    "            continue\n",
    "        if '-' in p or '#' in p:\n",
    "            continue\n",
    "        if '[' in p or ']' in p:\n",
    "            continue\n",
    "        if '—' in p or '$' in p:\n",
    "            continue\n",
    "        if '\"' in p or \"'\" in p:\n",
    "            continue\n",
    "        if '…' in p or '...' in p:\n",
    "            continue\n",
    "        if '•' in p or '!' in p:\n",
    "            continue\n",
    "        if '&' in p or ';' in p:\n",
    "            continue\n",
    "        if '–' in p or '“a' in p:\n",
    "            continue\n",
    "        if '&' in p or '“' in p or '”' in p:\n",
    "            continue\n",
    "        if ':' in p or '’' in p or '?' in p:\n",
    "            continue\n",
    "        if '/' in p:\n",
    "            p = p.split('/')\n",
    "            for word in p:\n",
    "                new_porter.add(word)\n",
    "            continue\n",
    "        if '.' in p:\n",
    "            p = p.strip('.')\n",
    "            p = ''.join(p.split('.'))\n",
    "        new_porter.add(p)\n",
    "    return list(new_porter)\n",
    "\n",
    "\n",
    "full_text = collect_and_trim_punctuation(new_books)\n",
    "\n",
    "tokenized_text = [PorterStemmer().stem(word) for word in full_text.split()]\n",
    "print('There are %i words in the Porter Stemmer tokenized text w/o other preprocessing' % (len(tokenized_text)))\n",
    "\n",
    "tokenized_text = porter_tokenizer(full_text)\n",
    "print('There are %i words in the Porter Stemmer tokenized text w/ other preprocessing' % (len(tokenized_text)))\n",
    "\n",
    "tokenized_text = [w for w in porter_tokenizer(full_text) if w not in stop]\n",
    "print('There are %i words in the Porter Stemmer tokenized text after removing stop words' % len(tokenized_text))\n",
    "\n",
    "tokenized_text = [w for w in porter_tokenizer(full_text) if (w not in stop) and (w not in name)]\n",
    "del tokenized_text[0] # Removes empty string from list\n",
    "print('There are %i words in the Porter Stemmer tokenized text after removing names' % len(tokenized_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We can see, then, that removing some of the text greatly reduce the number of word vectors we will need to create.\n",
    "\n",
    "\n",
    "Let's now try one-hot encoding these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of a copy of the newly formatted books : 2267\n"
     ]
    }
   ],
   "source": [
    "def generate_description_one_hot(descriptions):\n",
    "    offset = 84\n",
    "    desc_dict = dict()\n",
    "    for description in descriptions:\n",
    "        desc_dict[description] = offset\n",
    "        offset += 1\n",
    "    return desc_dict\n",
    "\n",
    "def reformat_descriptions(books_data):\n",
    "    reformatted_books_data = []\n",
    "    for book in books_data:\n",
    "        new_book = []\n",
    "        for index, info in enumerate(book):\n",
    "            if index == 84:\n",
    "                for i in range(len(descriptions)):\n",
    "                    new_book.append(0)\n",
    "            else:\n",
    "                new_book.append(info)\n",
    "        reformatted_books_data.append(new_book)\n",
    "    return reformatted_books_data\n",
    "\n",
    "def one_hot_descriptions(old_books, new_books, descriptions):\n",
    "    new_books = deepcopy(new_books)\n",
    "    for index, old_book in enumerate(old_books):\n",
    "        for description in descriptions:\n",
    "            if description in old_book[6]:\n",
    "                new_books[index][descriptions[description]] = 1\n",
    "    return new_books\n",
    "\n",
    "descriptions = generate_description_one_hot(tokenized_text)\n",
    "temp_books = reformat_descriptions(new_books)\n",
    "final_books = one_hot_descriptions(books, temp_books, descriptions)\n",
    "\n",
    "print('Length of a copy of the newly formatted books :', len(final_books[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Perfect!  The above with our data should be 2267.  Now let's start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels : 61\n",
      "Number of samples : 61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_labels(books):\n",
    "    books = deepcopy(books)\n",
    "    new_data = []\n",
    "    labels = []\n",
    "    for book in books:\n",
    "        item = book[0]\n",
    "        labels.append(float(item))\n",
    "        book.pop(0)\n",
    "        new_data.append(book)\n",
    "    return (np.asarray(new_data), np.asarray(labels))\n",
    "\n",
    "X_train, y_train = get_labels(final_books)\n",
    "\n",
    "print('Number of labels :', len(y_train))\n",
    "print('Number of samples :', len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Perfect again!  Let's try training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 7 samples\n",
      "Epoch 1/70\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 2/70\n",
      "54/54 [==============================] - 0s 963us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 3/70\n",
      "54/54 [==============================] - 0s 901us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 4/70\n",
      "54/54 [==============================] - 0s 756us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 5/70\n",
      "54/54 [==============================] - 0s 810us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 6/70\n",
      "54/54 [==============================] - 0s 697us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 7/70\n",
      "54/54 [==============================] - 0s 767us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 8/70\n",
      "54/54 [==============================] - 0s 684us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 9/70\n",
      "54/54 [==============================] - 0s 730us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 10/70\n",
      "54/54 [==============================] - 0s 799us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 11/70\n",
      "54/54 [==============================] - 0s 730us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 12/70\n",
      "54/54 [==============================] - 0s 727us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 13/70\n",
      "54/54 [==============================] - 0s 740us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 14/70\n",
      "54/54 [==============================] - 0s 746us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 15/70\n",
      "54/54 [==============================] - 0s 780us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 16/70\n",
      "54/54 [==============================] - 0s 699us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 17/70\n",
      "54/54 [==============================] - 0s 727us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 18/70\n",
      "54/54 [==============================] - 0s 741us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 19/70\n",
      "54/54 [==============================] - 0s 753us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 20/70\n",
      "54/54 [==============================] - 0s 768us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 21/70\n",
      "54/54 [==============================] - 0s 751us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 22/70\n",
      "54/54 [==============================] - 0s 756us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 23/70\n",
      "54/54 [==============================] - 0s 740us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 24/70\n",
      "54/54 [==============================] - 0s 746us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 25/70\n",
      "54/54 [==============================] - 0s 743us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 26/70\n",
      "54/54 [==============================] - 0s 747us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 27/70\n",
      "54/54 [==============================] - 0s 774us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 28/70\n",
      "54/54 [==============================] - 0s 846us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 29/70\n",
      "54/54 [==============================] - 0s 790us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 30/70\n",
      "54/54 [==============================] - 0s 823us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 31/70\n",
      "54/54 [==============================] - 0s 878us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 32/70\n",
      "54/54 [==============================] - 0s 793us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 33/70\n",
      "54/54 [==============================] - 0s 794us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 34/70\n",
      "54/54 [==============================] - 0s 717us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 35/70\n",
      "54/54 [==============================] - 0s 776us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 36/70\n",
      "54/54 [==============================] - 0s 722us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 37/70\n",
      "54/54 [==============================] - 0s 769us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 38/70\n",
      "54/54 [==============================] - 0s 725us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 39/70\n",
      "54/54 [==============================] - 0s 758us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 40/70\n",
      "54/54 [==============================] - 0s 737us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 41/70\n",
      "54/54 [==============================] - 0s 728us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 42/70\n",
      "54/54 [==============================] - 0s 771us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 43/70\n",
      "54/54 [==============================] - 0s 767us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 44/70\n",
      "54/54 [==============================] - 0s 774us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 45/70\n",
      "54/54 [==============================] - 0s 733us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 46/70\n",
      "54/54 [==============================] - 0s 724us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 47/70\n",
      "54/54 [==============================] - 0s 700us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 48/70\n",
      "54/54 [==============================] - 0s 740us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 49/70\n",
      "54/54 [==============================] - 0s 764us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 50/70\n",
      "54/54 [==============================] - 0s 811us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 51/70\n",
      "54/54 [==============================] - 0s 811us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 52/70\n",
      "54/54 [==============================] - 0s 777us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 53/70\n",
      "54/54 [==============================] - 0s 719us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 54/70\n",
      "54/54 [==============================] - 0s 804us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 55/70\n",
      "54/54 [==============================] - 0s 799us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 56/70\n",
      "54/54 [==============================] - 0s 709us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 57/70\n",
      "54/54 [==============================] - 0s 726us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 58/70\n",
      "54/54 [==============================] - 0s 704us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 59/70\n",
      "54/54 [==============================] - 0s 736us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 60/70\n",
      "54/54 [==============================] - 0s 724us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 61/70\n",
      "54/54 [==============================] - 0s 719us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 62/70\n",
      "54/54 [==============================] - 0s 758us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 63/70\n",
      "54/54 [==============================] - 0s 733us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 64/70\n",
      "54/54 [==============================] - 0s 715us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 65/70\n",
      "54/54 [==============================] - 0s 698us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 66/70\n",
      "54/54 [==============================] - 0s 711us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 67/70\n",
      "54/54 [==============================] - 0s 698us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 68/70\n",
      "54/54 [==============================] - 0s 684us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 69/70\n",
      "54/54 [==============================] - 0s 705us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "Epoch 70/70\n",
      "54/54 [==============================] - 0s 730us/step - loss: 6.4950 - val_loss: 15.9424\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "First 3 predictions:  [[1]\n",
      " [1]\n",
      " [1]]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-414-ab7baa336de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'First 3 predictions: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training accuracy: %.2f%%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(units=100, input_dim=X_train.shape[1],\n",
    "                             kernel_initializer='glorot_uniform',\n",
    "                             bias_initializer='zeros',\n",
    "                             activation='selu'))\n",
    "\n",
    "model.add(keras.layers.Dense(units=100, input_dim=100,\n",
    "                             kernel_initializer='glorot_uniform',\n",
    "                             bias_initializer='zeros',\n",
    "                             activation='selu'))\n",
    "\n",
    "model.add(keras.layers.Dense(units=1, input_dim=100, \n",
    "                             kernel_initializer='glorot_uniform',\n",
    "                             bias_initializer='zeros',\n",
    "                             activation='softmax'))\n",
    "\n",
    "# Using RMS Prop for better base performance and efficient activation; \n",
    "# need to play with decay rate\n",
    "sgd_optimizer = keras.optimizers.SGD(lr=0.0001, decay=1e-7, momentum=.9)\n",
    "adadelta_optimizer = keras.optimizers.Adadelta()\n",
    "rms_prop_optimizer = keras.optimizers.RMSprop()\n",
    "nadam_optimizer = keras.optimizers.Nadam()\n",
    "\n",
    "model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy')\n",
    "\n",
    "# Train with fit method\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=3, epochs=70, verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "# Predict class labels (return class labels as integers)\n",
    "y_train_pred = model.predict_classes(X_train, verbose=0)\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=1)\n",
    "\n",
    "print(y_train_pred)\n",
    "print(train_acc)\n",
    "print()\n",
    "print('First 3 predictions: ', y_train_pred[:3])\n",
    "print()\n",
    "print('Training accuracy: %.2f%%' % (train_acc * 100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
